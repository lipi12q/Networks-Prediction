{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2: Graph Mining\n",
    "*Due Wednesday November 14th, 2018 at 11:59 pm*\n",
    "\n",
    "*Notebook Author: Koki Sasagawa*\n",
    " \n",
    "Mining a large social network to uncover how well homophily can predict identity as well as the network structure. \n",
    "\n",
    "**Task1:** Link Predction - mostly complete social network that contains some large number of edges removed. Task is to predict up to 50 edges that system predicts to be most likely. \n",
    "\n",
    "## Data \n",
    "\n",
    "1. `network.tsv` - large social network specified in edge list format \n",
    "   - two columns where each column is label for a node in the graph\n",
    "   - undirected graph, thus order does not matter\n",
    "   - nodes assigned random numeric ID that have no meaning\n",
    "\n",
    "## Submission (modified after announcement) \n",
    "\n",
    "**Link prediction** should be a text file with two items on each line: node1 and node2  \n",
    "The first 50000 most likely links will be submitted. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a. Create graph by reading the tsv file with networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating network graph...\n",
      "Network graph created. Process took 302.3193 seconds\n",
      "Number of edges: 30915267\n",
      "Number of nodes: 6626753\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating network graph...\")\n",
    "start_time = time.time() \n",
    "\n",
    "with open(\"../data/network.tsv\", 'rb') as f:\n",
    "    grph = nx.read_edgelist(path=f, delimiter='\\t', encoding='utf8')\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Network graph created. Process took {:.04f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# Check that graph is of correct size\n",
    "print(\"Number of edges: {}\".format(grph.number_of_edges())) # There should be 30915267\n",
    "print(\"Number of nodes: {}\".format(grph.number_of_nodes())) # There should be 6626753"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. Create graph by reading the tsv file with pandas read_csv as chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read data as chunks\n",
    "# print(\"Reading network data as chunks...\")\n",
    "# start_time = time.time()\n",
    "\n",
    "# g_data_chunks = pd.read_csv(\"./all/network.tsv\",\n",
    "#                             delimiter='\\t',\n",
    "#                             usecols=[0,1],\n",
    "#                             names=['n', 'v'],\n",
    "#                             dtype={'n': np.int32, 'v': np.int32},\n",
    "#                             header=None,\n",
    "#                             chunksize=100000)\n",
    "\n",
    "# # Combine\n",
    "# # g_data_chunks pd.concat(g_data_chunks)\n",
    "\n",
    "# end_time = time.time()\n",
    "# print(\"Chunks created. Process took {:.04f} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Creating network graph...\")\n",
    "\n",
    "# start_time = time.time() \n",
    "\n",
    "# # Initalize undirected simple graph\n",
    "# grph = nx.Graph()\n",
    "\n",
    "# # Populate the graph by adding edges from chunked dataframes\n",
    "# for chunk in g_data_chunks: \n",
    "#   grph.add_edges_from([tuple(x) for x in chunk.values])\n",
    "\n",
    "# end_time = time.time()\n",
    "\n",
    "# print(\"Network graph created. Process took {:.04f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# # Check that graph is of correct size\n",
    "# print(\"Number of edges: {}\".format(grph.number_of_edges())) # There should be 30915267\n",
    "# print(\"Number of nodes: {}\".format(grph.number_of_nodes())) # There should be 6626753"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate an adjacency list and save it as a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken and modified from stack overflow: https://stackoverflow.com/\n",
    "# questions/34917550/write-a-graph-into-a-file-in-an-adjacency-list\n",
    "# -form-mentioning-all-neighbors-of\n",
    "def adj_list_to_file(G, file_name):\n",
    "    '''Create adjacency list and save as text file\n",
    "\n",
    "    :params G: network graph\n",
    "    :type G: networkx graph\n",
    "    :params file_name: file name and save location\n",
    "    :type file_name: str\n",
    "    '''\n",
    "\n",
    "    with open(file_name, \"w\") as f:\n",
    "        for n in G.nodes():\n",
    "            f.write(str(n) + ',')\n",
    "            for neighbor in G.neighbors(n):\n",
    "                f.write(str(neighbor) + ' ')\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write save save adjacency list \n",
    "adj_list_to_file(grph, '../data/adjacency_list.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read the adjacency list file and create a dictionary from it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file and create dictionary\n",
    "adj_list = {}\n",
    "\n",
    "with open('../data/adjacency_list.txt', 'r') as f:\n",
    "    # For each line in the file, create a dictionary that has a key = node and value = edges\n",
    "    for line in f:\n",
    "        adj_list[line.split(',')[0]] = line.split(',')[1].rstrip().split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The following functions are for the fast algorithm for Common Neighbors Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_lemma1(adj_list, L):\n",
    "    '''Filter nodes with neighbors less than or equal to L\n",
    "\n",
    "    If the number of their neighbors is no greater than threshold L,\n",
    "    these pairs will not have more than L common neighbors.\n",
    "\n",
    "    For example, the following is an adjacency list represented as a\n",
    "    python dictionary. The key is a node, and the value is a list of\n",
    "    common neighbors.\n",
    "\n",
    "    {0: [1, 2, 4, 5, 7],\n",
    "     1: [0, 2, 4, 7],\n",
    "     2: [0, 1, 3, 5, 6],\n",
    "     3: [2, 4, 6, 7],\n",
    "     4: [0, 1, 3, 6],\n",
    "     5: [0, 2],\n",
    "     6: [2, 3, 4],\n",
    "     7: [0, 1, 3]}\n",
    "\n",
    "    Setting L to 3, this function will filter out nodes that have\n",
    "    3 or less neighbors. The resulting nodes will be the following:\n",
    "\n",
    "    {0: [1, 2, 4, 5, 7],\n",
    "     1: [0, 2, 4, 7],\n",
    "     2: [0, 1, 3, 5, 6],\n",
    "     3: [2, 4, 6, 7],\n",
    "     4: [0, 1, 3, 6]}\n",
    "\n",
    "    :param adj_list: adjacency list\n",
    "    :type adj_list: dict\n",
    "    :param L: threshold for common neighbors\n",
    "    :type L: int\n",
    "    :return: adjacency list containing nodes with more than L neighbors\n",
    "    :rtype: dict\n",
    "    '''\n",
    "\n",
    "    adj_new = {}\n",
    "\n",
    "    for k, v in adj_list.items():\n",
    "        if len(v) > L:\n",
    "            adj_new[k] = v\n",
    "\n",
    "    return adj_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_adjacency_list(adj_list):\n",
    "    '''Invert the adjacency matrix.\n",
    "\n",
    "    For example, the following is an adjacency list represented as a\n",
    "    python dictionary. The key is a node, and the value is a list of\n",
    "    common neighbors of that node.\n",
    "\n",
    "    {0: [1, 2, 4, 5, 7],\n",
    "     1: [0, 2, 4, 7],\n",
    "     2: [0, 1, 3, 5, 6],\n",
    "     3: [2, 4, 6, 7],\n",
    "     4: [0, 1, 3, 6]}\n",
    "\n",
    "    Starting with node 1, we see that it appears in the adjacency\n",
    "    list of node 0, 2, and 4. Thus, the inverted representation will\n",
    "    be '1: [0, 2, 4]'. The resulting inverted adjaceny list will be\n",
    "    the following:\n",
    "\n",
    "    {0: [1, 2, 4],\n",
    "     1: [0, 2, 4],\n",
    "     2: [0, 1, 3],\n",
    "     3: [2, 4],\n",
    "     4: [0, 1, 3],\n",
    "     5: [0, 2],\n",
    "     6: [2, 3, 4],\n",
    "     7: [0, 1, 3]}\n",
    "\n",
    "    :param adj_list: adjacency list\n",
    "    :type adj_list: dict\n",
    "    :return: inverted adjacency list\n",
    "    :rtype: dict\n",
    "    '''\n",
    "\n",
    "    adj_inv = {}\n",
    "\n",
    "    for k, v in adj_list.items():\n",
    "        for i in v:\n",
    "            if i in adj_inv:\n",
    "                adj_inv[i].append(k)\n",
    "            else:\n",
    "                adj_inv[i] = [k]\n",
    "\n",
    "    return adj_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_accompanied_groups(adj_list):\n",
    "    '''Generate accompanying groups in (address, size) representation\n",
    "\n",
    "    For example, node 4 is present in the adjacency list of node 0.\n",
    "\n",
    "    {0: [1, 2, 4],\n",
    "     1: [0, 2, 4],\n",
    "     2: [0, 1, 3],\n",
    "     3: [2, 4],\n",
    "     4: [0, 1, 3],\n",
    "     5: [0, 2],\n",
    "     6: [2, 3, 4],\n",
    "     7: [0, 1, 3]}\n",
    "\n",
    "    Since this is the adjacency list of node 0, the address is 0. The\n",
    "    ranking of a node is equal to the size of the accompanied group.\n",
    "    For node 4, the size of the accompanying group '[1, 2]' is 2. The\n",
    "    accompanied group in the address, size representation would be\n",
    "    '{4: (0, 2)}'. The resulting accompanied groups will be the\n",
    "    following:\n",
    "\n",
    "    {1: [(2, 1), (4, 1), (7, 1)],\n",
    "     2: [(1, 1), (5, 1), (0, 1)],\n",
    "     3: [(2, 2), (4, 2), (7, 2), (6, 1)],\n",
    "     4: [(1, 2), (0, 2), (3, 1), (6, 2)]}\n",
    "\n",
    "    :param adj_list: inverted adjacency list\n",
    "    :type adj_list: dict\n",
    "    :param L: threshold for common neighbors\n",
    "    :type L: int\n",
    "    :return: accompanied groups in (adress, size) representation\n",
    "    :rtype: dict\n",
    "    '''\n",
    "\n",
    "    acc_group = {}\n",
    "\n",
    "    # Find accompanied groups of nodes by address and size\n",
    "    for k, v in adj_list.items():\n",
    "        for i in range(1, len(v)):\n",
    "            if v[i] in acc_group:\n",
    "                acc_group[v[i]].append((k, i))\n",
    "            else:\n",
    "                acc_group[v[i]] = [(k, i)]\n",
    "\n",
    "    return acc_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_lemma2(acc_group, L):\n",
    "    '''Filter accompanying groups less than or equal to L\n",
    "\n",
    "    After filtering by lemma 1, if node 'u' appears at most in L\n",
    "    node adjacencies (having no greater than L accompanied groups),\n",
    "    the common neighbor of any node pair containing 'u' will be no\n",
    "    greater than L.\n",
    "\n",
    "    For example, the following is a python dictionary representing\n",
    "    the accompanied groups of a network.\n",
    "\n",
    "    {1: [(2, 1), (4, 1), (7, 1)],\n",
    "     2: [(1, 1), (5, 1), (0, 1)],\n",
    "     3: [(2, 2), (4, 2), (7, 2), (6, 1)],\n",
    "     4: [(1, 2), (0, 2), (3, 1), (6, 2)]}\n",
    "\n",
    "    Setting L to 3, this function will filter out nodes that have\n",
    "    3 or less groups. The resulting accompanied groups will be the\n",
    "    following:\n",
    "\n",
    "    {3: [(2, 2), (4, 2), (7, 2), (6, 1)],\n",
    "     4: [(1, 2), (0, 2), (3, 1), (6, 2)]}\n",
    "\n",
    "    :param acc_group: accompanied groups\n",
    "    :type acc_group: dict\n",
    "    :param L: threshold for common neighbors\n",
    "    :type L: int\n",
    "    :return: accompanied groups greater than L\n",
    "    :rtype: dict\n",
    "    '''\n",
    "\n",
    "    f_acc_group = {}\n",
    "\n",
    "    # Filter by L\n",
    "    for k, v in acc_group.items():\n",
    "        if len(v) > L:\n",
    "            f_acc_group[k] = v\n",
    "\n",
    "    return f_acc_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_node_pairs(acc_group, adj_list, L):\n",
    "    '''Generate node pairs with CN greater than L.\n",
    "\n",
    "    For example, the following is a python dictionary representing\n",
    "    the accompanied groups of a network.\n",
    "\n",
    "    {3: [(2, 2), (4, 2), (7, 2), (6, 1)],\n",
    "     4: [(1, 2), (0, 2), (3, 1), (6, 2)]}\n",
    "\n",
    "    Rember that the accompanied groups are in (address, size) format.\n",
    "    Looking at the first group for node 4, the address is pointing to\n",
    "    adjacency list 1, and the size is 2. Take a look at the following\n",
    "    adjacency list:\n",
    "\n",
    "    {0: [1, 2, 4],\n",
    "     1: [0, 2, 4],\n",
    "     2: [0, 1, 3],\n",
    "     3: [2, 4],\n",
    "     4: [0, 1, 3],\n",
    "     5: [0, 2],\n",
    "     6: [2, 3, 4],\n",
    "     7: [0, 1, 3]}\n",
    "\n",
    "    Looking at node 1's adjacency list, the 2 other nodes accompanying\n",
    "    node 4 are 0 and 2. This means that node 0, 2, and 4 share the same\n",
    "    common neighbor node 1. If we look up the address and size for all\n",
    "    groups and calculate the total common neighbors shared, we get the\n",
    "    following:\n",
    "\n",
    "       |_0_|_1_|_2_|_3_|\n",
    "     3 | 3 | 2 | 2 |   |\n",
    "     4 | 1 | 1 | 1 | 1 |\n",
    "\n",
    "    :param acc_group: accompanied groups\n",
    "    :type acc_group: dict\n",
    "    :param adj_list: inverted adjacency list\n",
    "    :type adj_list: dict\n",
    "    :return: node pairs and CN values\n",
    "    :rtype: list\n",
    "    '''\n",
    "\n",
    "    node_pairs = {}\n",
    "\n",
    "    for k, v in acc_group.items():\n",
    "        for i in v:\n",
    "            # Read adjaceny list up to size (rank)\n",
    "            for j in adj_list[i[0]][:i[1]]:\n",
    "                node_pairs[(k, j)] = node_pairs.get((k, j), 0) + 1\n",
    "\n",
    "    filtered_node_pairs = []\n",
    "\n",
    "    for k, v in node_pairs.items():\n",
    "        if v > L:\n",
    "            filtered_node_pairs.append((k, v))\n",
    "\n",
    "    return filtered_node_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST that the functions work properly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest \n",
    "\n",
    "class TestFilter(unittest.TestCase):\n",
    "    \n",
    "    # Run before every single test\n",
    "    def setUp(self):\n",
    "        self.threshold = 3\n",
    "        \n",
    "        self.adj_list_1 = {0: [1, 2, 4, 5, 7],\n",
    "                           1: [0, 2, 4, 7],\n",
    "                           2: [0, 1, 3, 5, 6],\n",
    "                           3: [2, 4, 6, 7],\n",
    "                           4: [0, 1, 3, 6],\n",
    "                           5: [0, 2],\n",
    "                           6: [2, 3, 4],\n",
    "                           7: [0, 1, 3]}\n",
    "        \n",
    "        self.adj_list_2 = {0: [1, 2, 4, 5, 7], \n",
    "                           1: [0, 2, 4, 7], \n",
    "                           2: [0, 1, 3, 5, 6], \n",
    "                           3: [2, 4, 6, 7], \n",
    "                           4: [0, 1, 3, 6]}\n",
    "                            \n",
    "        self.inv_list = {0: [1, 2, 4],\n",
    "                         1: [0, 2, 4],\n",
    "                         2: [0, 1, 3],\n",
    "                         3: [2, 4],\n",
    "                         4: [0, 1, 3],\n",
    "                         5: [0, 2],\n",
    "                         6: [2, 3, 4],\n",
    "                         7: [0, 1, 3]}\n",
    "        \n",
    "        self.acc_group_1 = {1: [(2, 1), (4, 1), (7, 1)],\n",
    "                            2: [(1, 1), (5, 1), (0, 1)],\n",
    "                            3: [(2, 2), (4, 2), (7, 2), (6, 1)],\n",
    "                            4: [(1, 2), (0, 2), (3, 1), (6, 2)]}\n",
    "        \n",
    "        self.acc_group_2 = {3: [(2, 2), (4, 2), (7, 2), (6, 1)], \n",
    "                            4: [(1, 2), (0, 2), (3, 1), (6, 2)]}\n",
    "        \n",
    "        self.pair_node = [((4, 2), 4)]\n",
    "    \n",
    "    def test_filter_lemma1(self):\n",
    "        #print(\"Test filter lemma 1...\")\n",
    "        self.assertEqual(filter_by_lemma1(self.adj_list_1, self.threshold), self.adj_list_2)\n",
    "    \n",
    "    def test_inverted_adjacency_list(self):\n",
    "        #print(\"Test inverted_adjacency...\")\n",
    "        self.assertEqual(invert_adjacency_list(self.adj_list_2), self.inv_list)\n",
    "    \n",
    "    def test_generate_accompanied_groups(self):\n",
    "        # print(\"Test both lemma filters...\")\n",
    "        self.assertCountEqual(generate_accompanied_groups(self.inv_list), self.acc_group_1)\n",
    "        \n",
    "    def test_filter_lemma2(self):\n",
    "        self.assertEqual(filter_by_lemma2(self.acc_group_1, self.threshold), self.acc_group_2)\n",
    "    \n",
    "    def test_pair_node(self):\n",
    "        self.assertEqual(generate_node_pairs(self.acc_group_2, self.inv_list, self.threshold), self.pair_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.005s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Optimal L value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold. Count candidates from 5 to 100 (increments of 5)\n",
    "# Count how many node pairs are above a certain threshold \n",
    "results = {}\n",
    "\n",
    "for L in range(0, 150, 1):\n",
    "    count = 0\n",
    "    for k, v in adj_list.items():\n",
    "        if len(v) > L:\n",
    "            count += 1\n",
    "    results[L] = count  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_count = pd.DataFrame.from_dict({'L':list(results.keys()), 'node_count': list(results.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the style of seaborn plot\n",
    "sns.set(style='darkgrid', palette='husl', font_scale=1.5)\n",
    "\n",
    "# Create matplotlib Figure and Axes object\n",
    "f, ax = plt.subplots(figsize=(15,9))\n",
    "\n",
    "# Create the plot\n",
    "g = sns.lineplot(x='L', y='node_count', markers=True, data=node_count)\n",
    "\n",
    "# Fine Tuning font size\n",
    "g.set_xlabel('L', fontsize=20)\n",
    "g.set_ylabel('Number of Nodes', fontsize=20)\n",
    "g.axes.set_title('Threshold to number of nodes', fontsize=30)\n",
    "\n",
    "# Display\n",
    "plt.show(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate candidate node pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Threshold\n",
    "L = 50\n",
    "\n",
    "print(\"Step 1: Filter adjacency list\")\n",
    "f_adj_list = filter_by_lemma1(adj_list, L)\n",
    "\n",
    "print(\"Step 2: Invert adjacency list\")\n",
    "inv_adj_list = invert_adjacency_list(f_adj_list)\n",
    "\n",
    "# Clear Variables\n",
    "f_adj_list = None\n",
    "\n",
    "print(\"Step 3: Create accompanied groups\")\n",
    "acc_groups = generate_accompanied_groups(inv_adj_list)\n",
    "\n",
    "print(\"Step 4: Filter accompanied groups\")\n",
    "f_acc_groups = filter_by_lemma2(acc_groups, L)\n",
    "\n",
    "# Clear variables\n",
    "acc_groups = None\n",
    "\n",
    "candidate_node_pairs = generate_node_pairs(f_acc_groups, inv_adj_list, L)\n",
    "print(\"Candidate node pairs generated!\")\n",
    "\n",
    "# Clear variables\n",
    "f_acc_groups = None\n",
    "inv_adj_list = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save candidate ndoes as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_candidate_pairs(c_pairs, file_name):\n",
    "    '''Save candidate pairs as csv file\n",
    "\n",
    "    :params c_pairs: candidate node pairs\n",
    "    :type c_pairs: nested list\n",
    "    :params file_name: file name and save location\n",
    "    :type file_name: str\n",
    "    '''\n",
    "\n",
    "    with open(file_name, \"w\") as f:\n",
    "        f.write('node1,node2,CN\\n')\n",
    "        for i in c_pairs:\n",
    "            f.write('{}, {}, {}\\n'.format(i[0][0], i[0][1], i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "save_candidate_pairs(candidate_node_pairs, '../data/candidate_pairs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resulting nodes are the node pairs that have common neighbors above a certain threshold. From this list, for nodes that are not yet already connected, find the 50,000 most likely pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open candidate nodes\n",
    "with open('../data/candidate_pairs.csv', 'r') as f:\n",
    "    # For each line in the file, create a dictionary that has a key = node and value = edges\n",
    "    for line in f:\n",
    "        n1, n2, v = line.rstrip('\\n').split(',')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231167\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "      <th>CN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1091804</td>\n",
       "      <td>967845</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1091804</td>\n",
       "      <td>1354523</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1091804</td>\n",
       "      <td>2309755</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4573414</td>\n",
       "      <td>967845</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4573414</td>\n",
       "      <td>1354523</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     node1    node2   CN\n",
       "0  1091804   967845   67\n",
       "1  1091804  1354523   51\n",
       "2  1091804  2309755   68\n",
       "3  4573414   967845  101\n",
       "4  4573414  1354523   54"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_nodes = pd.read_csv('../data/candidate_pairs.csv',\n",
    "                              dtype={'node1': np.int32, 'node2': np.int32, 'CN': np.int32})\n",
    "\n",
    "# Check\n",
    "print(candidate_nodes.shape[0])\n",
    "candidate_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "      <th>CN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140294</th>\n",
       "      <td>6247815</td>\n",
       "      <td>1542000</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123751</th>\n",
       "      <td>5401224</td>\n",
       "      <td>988315</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>304552</td>\n",
       "      <td>6314086</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123761</th>\n",
       "      <td>5401224</td>\n",
       "      <td>885348</td>\n",
       "      <td>521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123748</th>\n",
       "      <td>5401224</td>\n",
       "      <td>4930496</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          node1    node2   CN\n",
       "140294  6247815  1542000  593\n",
       "123751  5401224   988315  557\n",
       "3661     304552  6314086  545\n",
       "123761  5401224   885348  521\n",
       "123748  5401224  4930496  509"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by CN value\n",
    "candidate_nodes.sort_values('CN', inplace=True, ascending=False)\n",
    "candidate_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_prediction(c_pairs, adj_list, limit):\n",
    "    '''Infer the most likely links between nodes in static network\n",
    "\n",
    "    This function infers the mostly likely links between nodes\n",
    "    based on the number of common neighbors.\n",
    "\n",
    "    :params adj_list: adjacency list\n",
    "    :type adj_list: dict\n",
    "    :params c_pairs: candidate node pairs\n",
    "    :type c_pairs: pandas dataframe\n",
    "    :params limit: limit number of results returned\n",
    "    :type limit: int\n",
    "    :return: predicted links between nodes\n",
    "    :rtype: list\n",
    "    '''\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for i, r in c_pairs.iterrows():\n",
    "        if count <= limit:\n",
    "            # keys in the adj_list dict are string type\n",
    "            if str(r[1]) in adj_list.get(str(r[0]), 0):\n",
    "                continue\n",
    "            else:\n",
    "                predictions.append((r[0], r[1]))\n",
    "                count += 1\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_links = link_prediction(adj_list, candidate_nodes, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predicted_links(predicted_links, file_name):\n",
    "    with open(file_name, \"w\") as f:\n",
    "        for i in predicted_links:\n",
    "            f.write('{} {}\\n'.format(i[0], i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save \n",
    "save_predicted_links(predicted_links, '../data/predicted_links.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test that the output is a novel prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that results don't exist in adj_list already\n",
    "# In other words, they are newly infered links\n",
    "\n",
    "for i in predicted_links:\n",
    "    if str(i[1]) in adj_list.get(str(i[0]), 0):\n",
    "        print('Link between {} and {} already exists! This link is not a valid prediction.'.format(i[0], i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
