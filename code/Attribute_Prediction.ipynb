{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Graph Mining\n",
    "*Due Wednesday November 14th, 2018 at 11:59 pm*  \n",
    "*Notebook Author: Koki Sasagawa*\n",
    "\n",
    "Mining a large social network to uncover how well homophily can predict identity as well as the network structure. \n",
    "\n",
    "## Task 2:\n",
    "Attribute Prediction - most of the nodes in the social network are provided with one or more attributes that can be drawn from different types. (e.g., age, occupation, musical preference, etc. ) Predict the probabilities of attributes for a set of completely unlabeled nodes\n",
    "\n",
    "## Data\n",
    "1. `labeled-vertices.train.tsv` & `labeled-vertices.dev.tsv` & `unlabeled-verticies.test.tsv` \n",
    "   - users with attributes formatted as the following: \n",
    "\n",
    "   > - **vertex1** T1:3 T7:1 T4:2\n",
    "   > - **vertex2** T2:4\n",
    "   > - **vertex3** T4:3 T3:1\n",
    "   \n",
    "   - Each value is specified as `AttributeType:Value`\n",
    "   - Not every user will have their attributes listed \n",
    "   - Majority users should have at least 2 attribute set\n",
    "2. `unlabeled-verticies.test.txt` - list of vertices that we will predict attributes and their values for\n",
    "\n",
    "## Submission \n",
    "\n",
    "**Attribute prediction** should be a csv file with two columns: id and attr. \n",
    "The attr column should contain a space-deliminted list of the attributes you think the user with that id has. The file should have the following structure:\n",
    "\n",
    "> id, attr\n",
    "> \n",
    "> 123, T0:0 T1:1 \n",
    "\n",
    "## Running the Notebook\n",
    "This notebook requires the `nalgorithm.py` and `decorators.py` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nalgorithm import candidate_node\n",
    "from decorators import timer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating network graph...\n",
      "Network graph created. Process took 355.0810 seconds\n",
      "Number of edges: 30915267\n",
      "Number of nodes: 6626753\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating network graph...\")\n",
    "start_time = time.perf_counter() \n",
    "\n",
    "with open(\"../raw_data/network.tsv\", 'rb') as f:\n",
    "    grph = nx.read_edgelist(path=f, delimiter='\\t', encoding='utf8')\n",
    "\n",
    "end_time = time.perf_counter() \n",
    "print(\"Network graph created. Process took {:.04f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# Check that graph is of correct size\n",
    "print(\"Number of edges: {}\".format(grph.number_of_edges())) # There should be 30915267\n",
    "print(\"Number of nodes: {}\".format(grph.number_of_nodes())) # There should be 6626753"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load all files for attribute prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def load_data(file_name):\n",
    "    '''Load data in chunks and creates DataFrame'''\n",
    "    \n",
    "    chunks = pd.read_csv(file_name, \n",
    "                         delimiter='\\t',\n",
    "                         names=['id', 'attr'],\n",
    "                         header=None,\n",
    "                         chunksize=100000)\n",
    "\n",
    "    output = pd.concat(chunks)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running load_data...\n",
      "Finished in 0.3347s\n",
      "Total number of nodes: 662675\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2666403</td>\n",
       "      <td>T0:2 T1:99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2627940</td>\n",
       "      <td>T0:0 T1:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4843136</td>\n",
       "      <td>T0:0 T1:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5396835</td>\n",
       "      <td>T0:0 T1:1813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5438188</td>\n",
       "      <td>T0:1 T1:1733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id          attr\n",
       "0  2666403    T0:2 T1:99\n",
       "1  2627940    T0:0 T1:26\n",
       "2  4843136    T0:0 T1:26\n",
       "3  5396835  T0:0 T1:1813\n",
       "4  5438188  T0:1 T1:1733"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set = load_data('../raw_data/labeled-vertices.dev.tsv')\n",
    "\n",
    "print('Total number of nodes: {}'.format(dev_set.shape[0]))\n",
    "dev_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running load_data...\n",
      "Finished in 1.9837s\n",
      "Total number of nodes: 5301403\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5509623</td>\n",
       "      <td>T0:0 T1:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6334893</td>\n",
       "      <td>T0:0 T1:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1218900</td>\n",
       "      <td>T0:1 T1:2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3871398</td>\n",
       "      <td>T0:1 T1:2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3942361</td>\n",
       "      <td>T0:0 T1:3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       attr\n",
       "0  5509623  T0:0 T1:0\n",
       "1  6334893  T0:0 T1:1\n",
       "2  1218900  T0:1 T1:2\n",
       "3  3871398  T0:1 T1:2\n",
       "4  3942361  T0:0 T1:3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = load_data('../raw_data/labeled-vertices.train.tsv')\n",
    "\n",
    "print('Total number of nodes: {}'.format(train_set.shape[0]))\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note:** The following concatenation step was left out for the kaggle submission and all predictions were made using only the train_set. This error lead to many nodes with 'empty' attributes, leading to a lower performance score. Combining the two files improved the f1 score of the Adamic/Adar + Preferential Attachment predictions from 0.78475 to 0.81436. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nodes: 5964078\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5509623</td>\n",
       "      <td>T0:0 T1:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6334893</td>\n",
       "      <td>T0:0 T1:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1218900</td>\n",
       "      <td>T0:1 T1:2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3871398</td>\n",
       "      <td>T0:1 T1:2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3942361</td>\n",
       "      <td>T0:0 T1:3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       attr\n",
       "0  5509623  T0:0 T1:0\n",
       "1  6334893  T0:0 T1:1\n",
       "2  1218900  T0:1 T1:2\n",
       "3  3871398  T0:1 T1:2\n",
       "4  3942361  T0:0 T1:3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_set = pd.concat([train_set, dev_set]).reset_index(drop=True)\n",
    "tot_set = tot_set.drop_duplicates(keep='first')\n",
    "\n",
    "print('Total number of nodes: {}'.format(tot_set.shape[0]))\n",
    "tot_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in test set...\n",
      "Test set loaded. Process took 0.2055 seconds\n",
      "Total number of nodes: 662675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['4546232', '3711008', '6394112', '5883774', '2843733']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Reading in test set...')\n",
    "start_time = time.time()\n",
    "\n",
    "test_set = []\n",
    "\n",
    "with open('../raw_data/unlabeled-vertices.test.txt') as f:\n",
    "    for line in f:\n",
    "        test_set.append(line.rstrip())\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Test set loaded. Process took {:.04f} seconds\".format(end_time - start_time))\n",
    "\n",
    "print('Total number of nodes: {}'.format(len(test_set)))\n",
    "test_set[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate node pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jaccard similarity and Adamic/Adar similarity both require nodes to have common neighbors, or the similarity score will be zero. Preferential attachment, however, can still be calculated as it is based on the idea that nodes will attach to nodes of higher degree. For nodes where Jaccard and Adamic/Adar fail to produce a similarity score, use the node suggested by rules of preferential attachment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_node = timer(candidate_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.a. Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running candidate_node...\n",
      "Finished in 9.4290s\n"
     ]
    }
   ],
   "source": [
    "jaccard_similarity_nodes = candidate_node(test_set=test_set, grph=grph, algo_type='jaccard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b. Adamic/Adar Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running candidate_node...\n",
      "Finished in 3.8526s\n"
     ]
    }
   ],
   "source": [
    "adamic_adar_nodes = candidate_node(test_set=test_set, grph=grph, algo_type='adamic/adar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.c. Preferential Attachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running candidate_node...\n",
      "Finished in 2.1646s\n"
     ]
    }
   ],
   "source": [
    "preferential_attachment_nodes = candidate_node(test_set=test_set, grph=grph, algo_type='preferential attachment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Select between Jaccard similarity, Adamic/Adar, or preferential attachment node pairs for attribute predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 1. Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = {'id': test_set,\n",
    "          'attr': list(jaccard_similarity_nodes.values())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 2. Jaccard + Preferential Attachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = {'id': test_set,\n",
    "          'attr': list(jaccard_similarity_nodes.values()), \n",
    "          'attr2': list(preferential_attachment_nodes.values())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 3. Adamic/Adar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3 = {'id': test_set,\n",
    "          'attr': list(adamic_adar_nodes.values())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 4. Adamic/Adar + Preferential Attachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4 = {'id': test_set,\n",
    "          'attr': list(adamic_adar_nodes.values()), \n",
    "          'attr2': list(preferential_attachment_nodes.values())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select prediction of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(data_4)\n",
    "\n",
    "jaccard_similarity_node = None\n",
    "adamic_adar_nodes = None\n",
    "preferential_attachment_nodes = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine predictions from Jaccard or Adamic/Adar with preferential attachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing candidate nodes: 58932\n",
      "Replacing 0's with nodes from preferential attachment...\n",
      "Missing candidate nodes: 0\n"
     ]
    }
   ],
   "source": [
    "if len(predictions.columns) == 3: \n",
    "    # Number of times where candidate node does not exist\n",
    "    zeros = predictions.shape[0] - np.count_nonzero(predictions['attr'])\n",
    "    print(\"Missing candidate nodes: {}\".format(zeros))\n",
    "    \n",
    "    print('Replacing 0\\'s with nodes from preferential attachment...')\n",
    "    # Replace 0's with nodes selected by preferential attachment\n",
    "    predictions['attr'] = np.where(predictions['attr'] == 0, predictions['attr2'], predictions['attr'])\n",
    "    zeros = predictions.shape[0] - np.count_nonzero(predictions['attr'])\n",
    "    print(\"Missing candidate nodes: {}\".format(zeros))\n",
    "    \n",
    "    predictions.drop(['attr2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Obtain attributes for nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 662675 rows in the prediction dataframe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4546232</td>\n",
       "      <td>2494614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711008</td>\n",
       "      <td>2444912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6394112</td>\n",
       "      <td>6223074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5883774</td>\n",
       "      <td>4485305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2843733</td>\n",
       "      <td>3931905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     attr\n",
       "0  4546232  2494614\n",
       "1  3711008  2444912\n",
       "2  6394112  6223074\n",
       "3  5883774  4485305\n",
       "4  2843733  3931905"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"There are {} rows in the prediction dataframe\".format(predictions.shape[0]))\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype of id in tot_set is <class 'numpy.int64'>\n",
      "dtype of id in predictions is <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Check dtype\n",
    "print('dtype of id in tot_set is {}'.format(type(tot_set['id'][0])))\n",
    "print('dtype of id in predictions is {}'.format(type(predictions['attr'][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype of id in predictions is <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "# The values in the prediction dataframe are currently str type\n",
    "# convert them to int64 to allow merge with tot_set\n",
    "predictions = predictions.astype(dtype=np.int64, copy=True)\n",
    "print('dtype of id in predictions is {}'.format(type(predictions['attr'][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_x</th>\n",
       "      <th>attr_x</th>\n",
       "      <th>id_y</th>\n",
       "      <th>attr_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4546232</td>\n",
       "      <td>2494614</td>\n",
       "      <td>2494614.0</td>\n",
       "      <td>T0:0 T1:1766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711008</td>\n",
       "      <td>2444912</td>\n",
       "      <td>2444912.0</td>\n",
       "      <td>T0:0 T1:1762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6394112</td>\n",
       "      <td>6223074</td>\n",
       "      <td>6223074.0</td>\n",
       "      <td>T0:0 T1:1914 T8:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5883774</td>\n",
       "      <td>4485305</td>\n",
       "      <td>4485305.0</td>\n",
       "      <td>T0:0 T1:944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2843733</td>\n",
       "      <td>3931905</td>\n",
       "      <td>3931905.0</td>\n",
       "      <td>T0:0 T1:538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_x   attr_x       id_y             attr_y\n",
       "0  4546232  2494614  2494614.0       T0:0 T1:1766\n",
       "1  3711008  2444912  2444912.0       T0:0 T1:1762\n",
       "2  6394112  6223074  6223074.0  T0:0 T1:1914 T8:0\n",
       "3  5883774  4485305  4485305.0        T0:0 T1:944\n",
       "4  2843733  3931905  3931905.0        T0:0 T1:538"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = predictions.merge(tot_set, left_on='attr', right_on='id', how='left')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan values:\n",
      "id_x          0\n",
      "attr_x        0\n",
      "id_y      32765\n",
      "attr_y    32765\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('nan values:\\n{}'.format(results.isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 32765 nodes that we do not know attributes for. Our current method is unable to predict attributes for these nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4546232</td>\n",
       "      <td>T0:0 T1:1766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711008</td>\n",
       "      <td>T0:0 T1:1762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6394112</td>\n",
       "      <td>T0:0 T1:1914 T8:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5883774</td>\n",
       "      <td>T0:0 T1:944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2843733</td>\n",
       "      <td>T0:0 T1:538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id               attr\n",
       "0  4546232       T0:0 T1:1766\n",
       "1  3711008       T0:0 T1:1762\n",
       "2  6394112  T0:0 T1:1914 T8:0\n",
       "3  5883774        T0:0 T1:944\n",
       "4  2843733        T0:0 T1:538"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.drop(['attr_x', 'id_y'], inplace=True, axis=1)\n",
    "results.columns = ['id', 'attr']\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results contain 662675 nodes\n"
     ]
    }
   ],
   "source": [
    "print('Results contain {} nodes'.format(results.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save attribute predictions as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('../output/attribute_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the particular dataset, homophily does not appear to hold well. Again, homophily in a social context explains that people who share similarities in socially significant ways are more likely to be linked. A subgraph of the original graph was created using the neighboring nodes of a randomly selected node. For each node in the subgraph, we calculated the similarity scores with its neighbors (if any), and returned the highest similarity score which was plotted on a histogram. It appears that most of the similarity scores were on the lower end (right-skewed) except a few with high similarity scores, and most nodes did not share the same attributes as only 11 of 71 nodes did. Of nodes with matching attributes, it seems the majority had low similarity scores as well (right-skewed). \n",
    "\n",
    "# Future Approaches \n",
    "\n",
    "For the next steps, I would like to revise my current approach for attribute predictions and see how the algorithm can be improved by taking into account attribute trends. From observing the data, I realized that out of the three classes of attributes (T0, T1, and T8), T0 and T1 were far more prevalent than T8. Perhaps, in real life social network, T0 and T1 are attributes much more common among users, whereas T8 is rarer and much more specific. For example, in LinkedIn, T0 could be a user’s educational background which, whereas T8 could be a professional certification a user has obtained. On a business professional network, ones educational background is a common attribute included in many profiles, but much fewer individuals may have certifications listed, such as being certified doctor, lifeguard, lawyer, etc. \n",
    " \n",
    "For more common classes of attributes (T0, T1), I could develop an algorithm that counts and assigns the most common attribute shared among all nearest neighbors. For example, in a given scenario, if T0:1 was more common than T0:2 out of all nearest neighbors, then inherit T0:1. \n",
    "\n",
    "For rarer classes of attributes (T8), I would use my current method of inheriting the attribute of the most similar neighbor as calculated by the Adamic/Adar algorithm. In cases where multiple nodes have the same similarity score and also have different variations of the rare attribute, I could either select the winning attribute randomly or by frequency (e.g., T8:213 might be more common than T8:121, so inherit T8:213).\n",
    "\n",
    "Additionally, I would like to explore other algorithms, such as treating attributes as itemsets which can be used to build association rules (e.g, If T0:12 and T1:334 are present, then T8:123 is also likely to be present)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
