{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2: Graph Mining\n",
    "*Due Wednesday November 14th, 2018 at 11:59 pm*\n",
    "\n",
    "*Notebook Author: Koki Sasagawa*\n",
    "\n",
    "Mining a large social network to uncover how well homophily can predict identity as well as the network structure. \n",
    "\n",
    "**Task2:** Attribute Prediction - most of the nodes in the social network are provided with one or more attributes that can be drawn from different types. (e.g., age, occupation, musical preference, etc. ) Predict the probabilities of attributes for a set of completely unlabeled nodes\n",
    "\n",
    "## Data\n",
    "\n",
    "1. `labeled-vertices.train.tsv` & `labeled-vertices.dev.tsv` & `unlabeled-verticies.test.tsv` \n",
    "   - users with attributes formatted as the following: \n",
    "\n",
    "   > - **vertex1** T1:3 T7:1 T4:2\n",
    "   > - **vertex2** T2:4\n",
    "   > - **vertex3** T4:3 T3:1\n",
    "   \n",
    "   - Each value is specified as `AttributeType:Value`\n",
    "   - Not every user will have their attributes listed \n",
    "   - Majority users should have at least 2 attribute set\n",
    "2. `unlabeled-verticies.test.txt` - simply have list of vertices that should predict attributes and their values \n",
    "\n",
    "## Submission \n",
    "\n",
    "**Attribute prediction** should be a csv file with two columns: id and attr. \n",
    "The attr column should contain a space-deliminted list of the attributes you think the user with that id has. The file should have the following structure:\n",
    "\n",
    "> id, attr\n",
    "> \n",
    "> 123, T0:0 T1:1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "# import os\n",
    "# from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating network graph...\n",
      "Network graph created. Process took 277.1276 seconds\n",
      "Number of edges: 30915267\n",
      "Number of nodes: 6626753\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating network graph...\")\n",
    "start_time = time.time() \n",
    "\n",
    "with open(\"../data/network.tsv\", 'rb') as f:\n",
    "    grph = nx.read_edgelist(path=f, delimiter='\\t', encoding='utf8')\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Network graph created. Process took {:.04f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# Check that graph is of correct size\n",
    "print(\"Number of edges: {}\".format(grph.number_of_edges())) # There should be 30915267\n",
    "print(\"Number of nodes: {}\".format(grph.number_of_nodes())) # There should be 6626753"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load all files for attribute prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in dev set...\n",
      "Dev set loaded. Process took 0.2679 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2666403</td>\n",
       "      <td>T0:2 T1:99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2627940</td>\n",
       "      <td>T0:0 T1:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4843136</td>\n",
       "      <td>T0:0 T1:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5396835</td>\n",
       "      <td>T0:0 T1:1813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5438188</td>\n",
       "      <td>T0:1 T1:1733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id          attr\n",
       "0  2666403    T0:2 T1:99\n",
       "1  2627940    T0:0 T1:26\n",
       "2  4843136    T0:0 T1:26\n",
       "3  5396835  T0:0 T1:1813\n",
       "4  5438188  T0:1 T1:1733"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Reading in dev set...\")\n",
    "start_time = time.time()\n",
    "\n",
    "dev_set_chunks = pd.read_csv(\"../data2/labeled-vertices.dev.tsv\",\n",
    "                      delimiter='\\t',\n",
    "                      usecols=[0,1],\n",
    "                      names=['id', 'attr'],\n",
    "                      header=None,\n",
    "                      chunksize=100000)\n",
    "\n",
    "dev_set = pd.concat(dev_set_chunks)\n",
    "\n",
    "# Free memory \n",
    "dev_set_chunks = None\n",
    "\n",
    "# with open('../data2/labeled-vertices.dev.test.tsv') as f:\n",
    "#     for line in f:\n",
    "#         dev_set.append(line.rstrip())\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Dev set loaded. Process took {:.04f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# Check \n",
    "dev_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in training set...\n",
      "train set loaded. Process took 1.9288 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5509623</td>\n",
       "      <td>T0:0 T1:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6334893</td>\n",
       "      <td>T0:0 T1:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1218900</td>\n",
       "      <td>T0:1 T1:2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3871398</td>\n",
       "      <td>T0:1 T1:2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3942361</td>\n",
       "      <td>T0:0 T1:3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       attr\n",
       "0  5509623  T0:0 T1:0\n",
       "1  6334893  T0:0 T1:1\n",
       "2  1218900  T0:1 T1:2\n",
       "3  3871398  T0:1 T1:2\n",
       "4  3942361  T0:0 T1:3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Reading in training set...\")\n",
    "start_time = time.time()\n",
    "\n",
    "train_set_chunks = pd.read_csv(\"../data2/labeled-vertices.train.tsv\",\n",
    "                      delimiter='\\t',\n",
    "                      usecols=[0,1],\n",
    "                      names=['id', 'attr'],\n",
    "                      header=None,\n",
    "                      chunksize=100000)\n",
    "\n",
    "train_set = pd.concat(train_set_chunks)\n",
    "\n",
    "# Free memory \n",
    "train_set_chunks = None\n",
    "\n",
    "# with open('../data2/labeled-vertices.dev.test.tsv') as f:\n",
    "#     for line in f:\n",
    "#         dev_set.append(line.rstrip())\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Train set loaded. Process took {:.04f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# Check \n",
    "print(train_set.shape[0])\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in test set...\n",
      "Test set loaded. Process took 0.2228 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['4546232', '3711008', '6394112', '5883774', '2843733']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Reading in test set...')\n",
    "start_time = time.time()\n",
    "\n",
    "test_set = []\n",
    "\n",
    "with open('../data2/unlabeled-vertices.test.txt') as f:\n",
    "    for line in f:\n",
    "        test_set.append(line.rstrip())\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Test set loaded. Process took {:.04f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# Check \n",
    "test_set[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the functions for attribute prediction\n",
    "\n",
    "The following function will compute some similarity metric on the neighbors of a node, and the node will inherit the attributes of the highest scoring node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_jaccard_similarity(test_set, grph):\n",
    "    '''Calculate then jaccard similarity of neighbors and return the most similar node\n",
    "    \n",
    "    If jaccard similarity of two nodes is zero, return 0 \n",
    "    \n",
    "    :params test_set: target nodes we want to find the most similar neighbor for\n",
    "    :type test_set: list\n",
    "    :params grph: network containing target nodes\n",
    "    :type grph: networkx graph\n",
    "    :return: node and the most similar neighboring node\n",
    "    :rtype: dict\n",
    "    '''\n",
    "    \n",
    "    # Store results\n",
    "    sim_results = {}\n",
    "    \n",
    "    for i in test_set:      \n",
    "        nearest_neighbors = list(grph.neighbors(i))\n",
    "        # If a node only has only 1 neighbor, inherit that neighbors attributes \n",
    "        if len(nearest_neighbors) == 1: \n",
    "            sim_results[i] = nearest_neighbors[0]\n",
    "        else:\n",
    "            # Generate node-neighbor pairings \n",
    "            node_pairs = [(i, j) for j in nearest_neighbors]\n",
    "            preds = nx.jaccard_coefficient(grph, ebunch=node_pairs)\n",
    "\n",
    "            # Sort by similarity score\n",
    "            preds = list(preds)\n",
    "            preds.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "            # Take the node with highest sim score\n",
    "            # If similarity is 0, return 0\n",
    "            if preds[0][2] == 0.0:\n",
    "                sim_results[i] = 0\n",
    "            else:\n",
    "                sim_results[i] = preds[0][1]\n",
    "\n",
    "    return sim_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_adamic_adar_similarity(test_set, grph):\n",
    "    '''Calculate then adamic/adar similarity of neighbors and return the most similar node\n",
    "    \n",
    "    If adamic/adar similarity of two nodes is zero, return 0\n",
    "    \n",
    "    :params test_set: target nodes we want to find the most similar neighbor for\n",
    "    :type test_set: list \n",
    "    :params grph: network containing target nodes\n",
    "    :type grph: networkx graph\n",
    "    :return: node and the most similar neighboring node\n",
    "    :rtype: dict\n",
    "    '''\n",
    "    \n",
    "    # Store results\n",
    "    sim_results = {}\n",
    "    \n",
    "    for i in test_set:\n",
    "        nearest_neighbors = list(grph.neighbors(i))\n",
    "        # If a node only has only 1 neighbor, inherit that neighbors attributes \n",
    "        if len(nearest_neighbors) == 1: \n",
    "            sim_results[i] = nearest_neighbors[0]\n",
    "        else:\n",
    "            # Generate node-neighbor pairings \n",
    "            node_pairs = [(i, j) for j in nearest_neighbors]\n",
    "            preds = nx.adamic_adar_index(grph, ebunch=node_pairs)\n",
    "\n",
    "            # Sort by similarity score\n",
    "            preds = list(preds)\n",
    "            preds.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "            # Take the node with highest sim score\n",
    "            # If similarity is 0, return 0\n",
    "            if preds[0][2] == 0.0:\n",
    "                sim_results[i] = 0\n",
    "            else:\n",
    "                sim_results[i] = preds[0][1]\n",
    "\n",
    "    return sim_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_preferential_attachment_score(test_set, grph):\n",
    "    '''Calculate then preferential attachment scores of neighbors and return the highest scoring node\n",
    "    \n",
    "    :params test_set: target nodes we want to find the most similar neighbor for\n",
    "    :type test_set: list\n",
    "    :params grph: network containing target nodes\n",
    "    :type grph: networkx graph\n",
    "    :return: node and the most similar neighboring node\n",
    "    :rtype: dict\n",
    "    '''\n",
    "    \n",
    "    # Store results\n",
    "    sim_results = {}\n",
    "    \n",
    "    for i in test_set:\n",
    "        nearest_neighbors = list(grph.neighbors(i))\n",
    "        # If a node only has only 1 neighbor, inherit that neighbors attributes \n",
    "        if len(nearest_neighbors) == 1: \n",
    "            sim_results[i] = nearest_neighbors[0]\n",
    "        else:\n",
    "            # Generate node-neighbor pairings \n",
    "            node_pairs = [(i, j) for j in nearest_neighbors]\n",
    "            preds = nx.preferential_attachment(grph, ebunch=node_pairs)\n",
    "\n",
    "            # Sort by score\n",
    "            preds = list(preds)\n",
    "            preds.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "            # Take the node with highest score\n",
    "            # If score is 0, return 0\n",
    "            if preds[0][2] == 0.0:\n",
    "                sim_results[i] = 0\n",
    "            else:\n",
    "                sim_results[i] = preds[0][1]\n",
    "\n",
    "    return sim_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate node pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jaccard similarity and Adamic/adar similarity both require nodes to have common neighbors, or the similarity score will be zero. Preferential attachment, however, can still be calculated as it is based on the idea that nodes will attach to nodes of higher degree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jaccard similarity...\n",
      "Node pairs generated. Process took 31.3890 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Running jaccard similarity...')\n",
    "start_time = time.time()\n",
    "\n",
    "jaccard_similarity_nodes = highest_jaccard_similarity(test_set, grph)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Node pairs generated. Process took {:.04f} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running adamic/adar similarity...')\n",
    "start_time = time.time()\n",
    "\n",
    "adamic_adar_nodes = highest_adamic_adar_similarity(test_set, grph)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Node pairs generated. Process took {:.04f} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running preferential attachment...\n",
      "Node pairs generated. Process took 4.9312 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Running preferential attachment...')\n",
    "start_time = time.time()\n",
    "\n",
    "preferential_attachment_nodes = highest_preferential_attachment_score(test_set, grph)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Node pairs generated. Process took {:.04f} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\n",
    "                        'id': test_set,\n",
    "                        'jaccard_similarity': list(jaccard_similarity_nodes.values()), \n",
    "                        'preferential_attachment': list(preferential_attachment_nodes.values()),\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free memory of variables no longer used\n",
    "jaccard_similarity_nodes = None\n",
    "adamic_adar_nodes = None\n",
    "preferential_attachment_nodes = None\n",
    "grph = None\n",
    "del jaccard_similarity_nodes\n",
    "del adamic_adar_nodes\n",
    "del preferential_attachment_nodes\n",
    "del grph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "      <th>preferential_attachment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4546232</td>\n",
       "      <td>2494614</td>\n",
       "      <td>2494614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711008</td>\n",
       "      <td>2444912</td>\n",
       "      <td>2174169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6394112</td>\n",
       "      <td>6223074</td>\n",
       "      <td>6223074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5883774</td>\n",
       "      <td>2967901</td>\n",
       "      <td>4485305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2843733</td>\n",
       "      <td>3931905</td>\n",
       "      <td>3931905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id jaccard_similarity preferential_attachment\n",
       "0  4546232            2494614                 2494614\n",
       "1  3711008            2444912                 2174169\n",
       "2  6394112            6223074                 6223074\n",
       "3  5883774            2967901                 4485305\n",
       "4  2843733            3931905                 3931905"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0's: 58932\n"
     ]
    }
   ],
   "source": [
    "# Find the number of cells where jaccard similarity did not return a similarity score and returned 0\n",
    "print(\"Number of 0\\'s: {}\".format(predictions.shape[0] - np.count_nonzero(predictions['jaccard_similarity'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every row where jaccard similarity failed to return a candidate node due to lack of common neighbors,\n",
    "# use the node returned by preferential attachment\n",
    "predictions['attr'] = np.where(predictions['jaccard_similarity'] == 0, predictions['preferential_attachment'], predictions['jaccard_similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0's: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of 0\\'s: {}\".format(predictions.shape[0] - np.count_nonzero(predictions['attr'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We no longer need columns jaccard_similarity and preferential attachment, so drop them\n",
    "predictions.drop(['jaccard_similarity', 'preferential_attachment'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4546232</td>\n",
       "      <td>2494614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711008</td>\n",
       "      <td>2444912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6394112</td>\n",
       "      <td>6223074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5883774</td>\n",
       "      <td>2967901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2843733</td>\n",
       "      <td>3931905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     attr\n",
       "0  4546232  2494614\n",
       "1  3711008  2444912\n",
       "2  6394112  6223074\n",
       "3  5883774  2967901\n",
       "4  2843733  3931905"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_attributes(node_pairs, attr_set):\n",
    "    '''Retrieve the corresponding attributes from the trainset\n",
    "    \n",
    "    :params node_pairs: nodes with unknown attributes\n",
    "    :type node_pairs: pandas dataframe \n",
    "    :params attr_set: nodes with known attributes\n",
    "    :type attr_set: pandas dataframe\n",
    "    :return: predicted attributes \n",
    "    :rtype: list\n",
    "    '''\n",
    "    \n",
    "    count = 0 \n",
    "    \n",
    "    pred_attr = []\n",
    "    \n",
    "    all_nodes = set(node_pairs['attr'])\n",
    "    \n",
    "    print('Getting attributes...')\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i, r in attr_set.iterrows():\n",
    "        print(r[0])\n",
    "        print(r[1])\n",
    "        break\n",
    "    # Find the corresponding attributes from the trainset\n",
    "#     for i in node_pairs['attr']:\n",
    "#         count += 1 \n",
    "#         if count <= 10:\n",
    "# #             attribute = attr_set[attr_set['id'] == int(i)]['attr']\n",
    "# #             if attribute.empty:\n",
    "# #                 pred_attr.append(None)\n",
    "# #             else:\n",
    "# #                 pred_attr.append(attribute.values[0])\n",
    "    \n",
    "#             attribute = attr_set.loc[attr_set['id'] == int(i), 'attr']\n",
    "#             if attribute.empty:\n",
    "#                 pred_attr.append(None)\n",
    "#             else:\n",
    "#                 pred_attr.append(attribute.values[0])\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Attributes found. Process took {:.04f} seconds\".format(end_time - start_time))\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "#     for i in node_pairs['attr']:\n",
    "#         attribute = attr_set.loc[attr_set['id'] == int(i), 'attr']\n",
    "#         if attribute.empty:\n",
    "#             pred_attr.append(None)\n",
    "#         else:\n",
    "#             pred_attr.append(attribute.values[0])\n",
    "        \n",
    "#     return pred_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting attributes...\n",
      "5509623\n",
      "T0:0 T1:0\n",
      "Attributes found. Process took 0.7670 seconds\n"
     ]
    }
   ],
   "source": [
    "find_attributes(predictions, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting attributes...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-71cc688fbd6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fill attr column with predicted attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-149-bd38aea3263a>\u001b[0m in \u001b[0;36mfind_attributes\u001b[0;34m(node_pairs, attr_set)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Find the corresponding attributes from the trainset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mattribute\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'attr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mpred_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Learning/UMICH_course_material/SI_671_Data_Mining/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[0;32m~/Documents/Learning/UMICH_course_material/SI_671_Data_Mining/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid type comparison\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Getting attributes...')\n",
    "start_time = time.time()\n",
    "\n",
    "# Fill attr column with predicted attributes \n",
    "predictions['attr'] = find_attributes(predictions, train_set)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Attributes found. Process took {:.04f} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Use the common neighbor node pairs produced from the link prediction problem and find the node with the highest CN value and inherit their attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231167\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "      <th>CN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1091804</td>\n",
       "      <td>967845</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1091804</td>\n",
       "      <td>1354523</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1091804</td>\n",
       "      <td>2309755</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4573414</td>\n",
       "      <td>967845</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4573414</td>\n",
       "      <td>1354523</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     node1    node2   CN\n",
       "0  1091804   967845   67\n",
       "1  1091804  1354523   51\n",
       "2  1091804  2309755   68\n",
       "3  4573414   967845  101\n",
       "4  4573414  1354523   54"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_pairs = candidate_nodes = pd.read_csv('../data/candidate_pairs.csv',\n",
    "                              dtype={'node1': np.int32, 'node2': np.int32, 'CN': np.int32})\n",
    "\n",
    "# Check\n",
    "print(candidate_nodes.shape[0])\n",
    "candidate_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropping duplicates: 693501\n",
      "Number of rows after dropping duplicates: 52395\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "      <th>CN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6247815</td>\n",
       "      <td>1542000</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5401224</td>\n",
       "      <td>988315</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304552</td>\n",
       "      <td>6314086</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>353603</td>\n",
       "      <td>988315</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4258628</td>\n",
       "      <td>1542000</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     node1    node2   CN\n",
       "0  6247815  1542000  593\n",
       "1  5401224   988315  557\n",
       "2   304552  6314086  545\n",
       "5   353603   988315  497\n",
       "6  4258628  1542000  496"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by CN value and reset index\n",
    "candidate_nodes.sort_values('CN', inplace=True, ascending=False)\n",
    "candidate_nodes.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print('Number of rows before dropping duplicates: {}'.format(candidate_nodes.size))\n",
    "\n",
    "# Drop duplicates. The first match we get is the one with the highest CN.\n",
    "candidate_nodes.drop_duplicates(subset='node1', keep='first', inplace=True)\n",
    "\n",
    "print('Number of rows after dropping duplicates: {}'.format(candidate_nodes.size))\n",
    "candidate_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         True\n",
      "1         True\n",
      "2         True\n",
      "5         True\n",
      "6         True\n",
      "7         True\n",
      "8         True\n",
      "9         True\n",
      "10        True\n",
      "11        True\n",
      "12        True\n",
      "13        True\n",
      "14        True\n",
      "15        True\n",
      "16        True\n",
      "17        True\n",
      "19        True\n",
      "20        True\n",
      "21        True\n",
      "23        True\n",
      "25        True\n",
      "26        True\n",
      "27        True\n",
      "28        True\n",
      "29        True\n",
      "31        True\n",
      "32        True\n",
      "38        True\n",
      "41        True\n",
      "42        True\n",
      "          ... \n",
      "230561    True\n",
      "230566    True\n",
      "230584    True\n",
      "230595    True\n",
      "230598    True\n",
      "230602    True\n",
      "230619    True\n",
      "230637    True\n",
      "230652    True\n",
      "230656    True\n",
      "230677    True\n",
      "230720    True\n",
      "230722    True\n",
      "230725    True\n",
      "230743    True\n",
      "230745    True\n",
      "230753    True\n",
      "230775    True\n",
      "230843    True\n",
      "230846    True\n",
      "230865    True\n",
      "230902    True\n",
      "230927    True\n",
      "230945    True\n",
      "230985    True\n",
      "231004    True\n",
      "231061    True\n",
      "231156    True\n",
      "231158    True\n",
      "231162    True\n",
      "Name: node1, Length: 17465, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "for i in test_set:\n",
    "    for i, r in c_pairs.iterrows()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140294\n"
     ]
    }
   ],
   "source": [
    "for i in test_set:\n",
    "    print(candidate_nodes.node1.ne(int(i)).idxmin())\n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2494614']\n",
      "['2120159', '3119624', '2817288', '848669', '4546232', '1242663', '3191796']\n"
     ]
    }
   ],
   "source": [
    "# Solution 1: Take advantage of the common neighbors data produced earlier to find candidata nodes for a node.\n",
    "# Assume their attributes will be shared with the mystery node. \n",
    "count = 0\n",
    "for i in test_set:\n",
    "    print(adj_list[i])\n",
    "    print(adj_list[adj_list[i][0]])\n",
    "    count += 1 \n",
    "    if count == 1:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following intuition:\n",
    "1. Nodes sharing common neighbors are likely to be friends, thus share similar interests. Jaccard_similarity to find the most similar node. \n",
    "2. For nodes with few neighbors, if nodes are closer than 4 nodes away (small world phenomenon states that on averages nodes are 4 steps aways), find those nodes, rank them by connetivity (preferential attachment) and inherit the attributes of the node with the highest degree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a user x user matrix, and have the value b 0 or 1 to indicate a link. \n",
    "# Using cosine similarity, the most similar node will be returned for a target node\n",
    "# Using the similar node, use that as a key to look up its node in the training set.\n",
    "# Retrieve its attributes and assign that as the attribute for the particular node. \n",
    "\n",
    "# If multiple nodes exists, for example, using a threshold to define similarity, \n",
    "# choose the nearest one. Perhaps, I can find the shortest path for node1 - candidate node\n",
    "# then choose the closest one. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a adjacency matrix, we can assume that popular neighbors have more influence than less coneccted neighbors.\n",
    "# For a given node, find all  neighbors.\n",
    "# Return the \"most\" connected neighbor and their attributes.\n",
    "# These attributes can be the new attributes for the user. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triangular closure can indicate tight community of friends.\n",
    "# if a nighbor of a friend is friends with another nieghbor, this triangualr relationship can indicate close nit \n",
    "# circle, assume that these nodes share alot of attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD approach\n",
    "# Create a user x attribute matrix\n",
    "# presence of attribute is indicated by 1, absence is 0,\n",
    "# use this "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
