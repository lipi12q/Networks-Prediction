{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2: Graph Mining\n",
    "*Due Wednesday November 14th, 2018 at 11:59 pm*\n",
    "\n",
    "*Notebook Author: Koki Sasagawa*\n",
    "\n",
    "Mining a large social network to uncover how well homophily can predict identity as well as the network structure. \n",
    "\n",
    "**Task2:** Attribute Prediction - most of the nodes in the social network are provided with one or more attributes that can be drawn from different types. (e.g., age, occupation, musical preference, etc. ) Predict the probabilities of attributes for a set of completely unlabeled nodes\n",
    "\n",
    "## Data\n",
    "\n",
    "1. `labeled-vertices.train.tsv` & `labeled-vertices.dev.tsv` & `unlabeled-verticies.test.tsv` \n",
    "   - users with attributes formatted as the following: \n",
    "\n",
    "   > - **vertex1** T1:3 T7:1 T4:2\n",
    "   > - **vertex2** T2:4\n",
    "   > - **vertex3** T4:3 T3:1\n",
    "   \n",
    "   - Each value is specified as `AttributeType:Value`\n",
    "   - Not every user will have their attributes listed \n",
    "   - Majority users should have at least 2 attribute set\n",
    "2. `unlabeled-verticies.test.txt` - simply have list of vertices that should predict attributes and their values \n",
    "\n",
    "## Submission \n",
    "\n",
    "**Attribute prediction** should be a csv file with two columns: id and attr. \n",
    "The attr column should contain a space-deliminted list of the attributes you think the user with that id has. The file should have the following structure:\n",
    "\n",
    "> id, attr\n",
    "> \n",
    "> 123, T0:0 T1:1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "import time\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open file and create dictionary \n",
    "# adj_list = {}\n",
    "\n",
    "# with open('../data/adjacency_list.txt', 'r') as f:\n",
    "#     # For each line in the file, create a dictionary that has a key = node and value = edges\n",
    "#     for line in f:\n",
    "#         adj_list[line.split(',')[0]] = line.split(',')[1].rstrip().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating network graph...\n",
      "Network graph created. Process took 251.0850 seconds\n",
      "Number of edges: 30915267\n",
      "Number of nodes: 6626753\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating network graph...\")\n",
    "start_time = time.time() \n",
    "\n",
    "with open(\"../data/network.tsv\", 'rb') as f:\n",
    "    grph = nx.read_edgelist(path=f, delimiter='\\t', encoding='utf8')\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Network graph created. Process took {:.04f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# Check that graph is of correct size\n",
    "print(\"Number of edges: {}\".format(grph.number_of_edges())) # There should be 30915267\n",
    "print(\"Number of nodes: {}\".format(grph.number_of_nodes())) # There should be 6626753"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in test set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['4546232', '3711008', '6394112', '5883774', '2843733']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Reading in test set...')\n",
    "start_time = time.time()\n",
    "\n",
    "test_set = []\n",
    "\n",
    "with open('../data2/unlabeled-vertices.test.txt') as f:\n",
    "    for line in f:\n",
    "        test_set.append(line.rstrip())\n",
    "\n",
    "# Check \n",
    "test_set[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 neighbor: (4546232, 2494614)\n",
      "Before sorting: [('3711008', '2444912', 0.07142857142857142), ('3711008', '2582444', 0.004761904761904762), ('3711008', '2174169', 0.0022624434389140274)]\n",
      "After sorting: [('3711008', '2444912', 0.07142857142857142), ('3711008', '2582444', 0.004761904761904762), ('3711008', '2174169', 0.0022624434389140274)]\n",
      "2444912\n",
      "1 neighbor: (6394112, 6223074)\n",
      "Before sorting: [('5883774', '2967901', 0.07692307692307693), ('5883774', '4485305', 0.045454545454545456)]\n",
      "After sorting: [('5883774', '2967901', 0.07692307692307693), ('5883774', '4485305', 0.045454545454545456)]\n",
      "2967901\n",
      "1 neighbor: (2843733, 3931905)\n",
      "1 neighbor: (2571713, 26197)\n",
      "1 neighbor: (1672856, 2305106)\n",
      "1 neighbor: (1899234, 923650)\n",
      "Before sorting: [('1257763', '1096777', 0.0), ('1257763', '2650764', 0.0)]\n",
      "After sorting: [('1257763', '1096777', 0.0), ('1257763', '2650764', 0.0)]\n",
      "{'4546232': '2494614', '3711008': '2444912', '6394112': '6223074', '5883774': '2967901', '2843733': '3931905', '2571713': '26197', '1672856': '2305106', '1899234': '923650', '1257763': 0}\n"
     ]
    }
   ],
   "source": [
    "# Find the jaccard similarity between two nodes, and return the highest similarity pair \n",
    "# One with the highest similarity value --> inherit their values \n",
    "\n",
    "def highest_jaccard_similarity(test_set):\n",
    "    '''Calculate then jaccard similarity of neighbors and return the most similar node\n",
    "    \n",
    "    If jaccard similarity of two nodes is zero, return None. \n",
    "    \n",
    "    :params test_set: target nodes we wan to find the most similar to\n",
    "    :type test_set: list \n",
    "    :return: node and their most similar neighboring node\n",
    "    :rtype: dict\n",
    "    '''\n",
    "    \n",
    "    # For testing\n",
    "    count = 0 \n",
    "    \n",
    "    # Store results\n",
    "    sim_results = {}\n",
    "    \n",
    "    for i in test_set:\n",
    "        \n",
    "        count += 1 \n",
    "        if count < 10:\n",
    "            nearest_neighbors = list(grph.neighbors(i))\n",
    "            # If a node only has only 1 neighbor, inherit that neighbors attributes \n",
    "            if len(nearest_neighbors) == 1: \n",
    "                print('1 neighbor: ({}, {})'.format(i, nearest_neighbors[0]))\n",
    "                sim_results[i] = nearest_neighbors[0]\n",
    "            else:\n",
    "                # Generate node-neighbor pairings \n",
    "                node_pairs = [(i, j) for j in nearest_neighbors]\n",
    "                preds = nx.jaccard_coefficient(grph, ebunch=node_pairs)\n",
    "                \n",
    "                # Sort by similarity score\n",
    "                preds = list(preds)\n",
    "                print('Before sorting: {}'.format(preds))\n",
    "                preds.sort(key=lambda x: x[2], reverse=True)\n",
    "                print('After sorting: {}'.format(preds))\n",
    "                \n",
    "                # Take the node with highest sim score\n",
    "                # If similarity is 0, return 0\n",
    "                if preds[0][2] == 0.0:\n",
    "                    sim_results[i] = 0\n",
    "                else:\n",
    "                    print(preds[0][1])\n",
    "                    sim_results[i] = preds[0][1]\n",
    "\n",
    "    return sim_results\n",
    "\n",
    "# Run \n",
    "prediction_1 = highest_jaccard_similarity(test_set)\n",
    "print(prediction_1)\n",
    "\n",
    "# print(sim_results)\n",
    "\n",
    "#         # From specified node in graph, perform dfs of 2 to find relevant neighbors \n",
    "#         sub_grph = nx.dfs_edges(grph, source=i, depth_limit=2)\n",
    "\n",
    "# predicted_df = pd.DataFrame.from_dict(predicted_dict, orient='index', columns = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 neighbor: 4546232, ['2494614']\n",
      "Before sorting: [('3711008', '2444912', 81), ('3711008', '2582444', 624), ('3711008', '2174169', 1320)]\n",
      "After sorting: [('3711008', '2174169', 1320), ('3711008', '2582444', 624), ('3711008', '2444912', 81)]\n",
      "[]\n",
      "1 neighbor: 6394112, ['6223074']\n",
      "Before sorting: [('5883774', '2967901', 24), ('5883774', '4485305', 42)]\n",
      "After sorting: [('5883774', '4485305', 42), ('5883774', '2967901', 24)]\n",
      "[]\n",
      "1 neighbor: 2843733, ['3931905']\n",
      "1 neighbor: 2571713, ['26197']\n",
      "1 neighbor: 1672856, ['2305106']\n",
      "1 neighbor: 1899234, ['923650']\n",
      "Before sorting: [('1257763', '1096777', 10), ('1257763', '2650764', 92)]\n",
      "After sorting: [('1257763', '2650764', 92), ('1257763', '1096777', 10)]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "def highest_adamic_adar_similarity(test_set):\n",
    "    '''Calculate then adamic/adar similarity of neighbors and return the most similar node\n",
    "    \n",
    "    :params test_set: target nodes we wan to find the most similar to\n",
    "    :type test_set: list \n",
    "    :return: node and their most similar neighboring node\n",
    "    :rtype: dict\n",
    "    '''\n",
    "    \n",
    "    # For testing\n",
    "    count = 0 \n",
    "    \n",
    "    # Store results\n",
    "    sim_results = {}\n",
    "    \n",
    "    for i in test_set:\n",
    "        \n",
    "        count += 1 \n",
    "        if count < 10:\n",
    "            nearest_neighbors = list(grph.neighbors(i))\n",
    "            # If a node only has only 1 neighbor, inherit that neighbors attributes \n",
    "            if len(nearest_neighbors) == 1: \n",
    "                print('1 neighbor: {}, {}'.format(i, nearest_neighbors))\n",
    "                sim_results[i] = nearest_neighbors\n",
    "            else:\n",
    "                # Generate node-neighbor pairings \n",
    "                node_pairs = [(i, j) for j in nearest_neighbors]\n",
    "                preds = nx.preferential_attachment(grph, ebunch=node_pairs)\n",
    "                \n",
    "                # Sort by similarity score\n",
    "                preds = list(preds)\n",
    "                print('Before sorting: {}'.format(preds))\n",
    "                preds.sort(key=lambda x: x[2], reverse=True)\n",
    "                print('After sorting: {}'.format(preds))\n",
    "                \n",
    "                ties = [] \n",
    "                \n",
    "                # Check for ties in similarity values \n",
    "                for i in range(1, len(preds)): \n",
    "                    if preds[i][2] == preds[i-1][2]:\n",
    "                        ties.append(grph.degree(preds[i-1][1]))\n",
    "                \n",
    "                print(ties)\n",
    "                \n",
    "highest_adamic_adar_similarity(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate candidate node pairs by CN\n",
    "\n",
    "The exponential growth in nodes start around threshold L < 10, thus we will define the threshold at 15 to be able to calculate the CN for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define Threshold\n",
    "# L = 15\n",
    "\n",
    "# print(\"Step 1: Filter adjacency list\")\n",
    "# f_adj_list = filter_by_lemma1(adj_list, L)\n",
    "\n",
    "# print(\"Step 2: Invert adjacency list\")\n",
    "# inv_adj_list = invert_adjacency_list(f_adj_list)\n",
    "\n",
    "# # Clear Variables\n",
    "# f_adj_list = None\n",
    "\n",
    "# print(\"Step 3: Create accompanied groups\")\n",
    "# acc_groups = generate_accompanied_groups(inv_adj_list)\n",
    "\n",
    "# print(\"Step 4: Filter accompanied groups\")\n",
    "# f_acc_groups = filter_by_lemma2(acc_groups, L)\n",
    "\n",
    "# # Clear variables\n",
    "# acc_groups = None\n",
    "\n",
    "# candidate_node_pairs = generate_node_pairs(f_acc_groups, inv_adj_list, L)\n",
    "# print(\"Candidate node pairs generated!\")\n",
    "\n",
    "# # Clear variables\n",
    "# f_acc_groups = None\n",
    "# inv_adj_list = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data for attribute prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in adjacnecy list and creating dictionary...\n",
      "Adjacency list loaded. Process took 26.0404 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print('Reading in adjacnecy list and creating dictionary...')\n",
    "\n",
    "# Read adjacency list\n",
    "adj_list = {}\n",
    "\n",
    "with open('../data/adjacency_list.txt', 'r') as f:\n",
    "    # For each line in the file, create a dictionary that has a key = node and value = edges\n",
    "    for line in f:\n",
    "        adj_list[line.split(',')[0]] = line.split(',')[1].rstrip().split(' ')\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Adjacency list loaded. Process took {:.04f} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in test set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['4546232', '3711008', '6394112', '5883774', '2843733']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print('Reading in test set...')\n",
    "\n",
    "test_set = []\n",
    "\n",
    "with open('../data2/unlabeled-vertices.test.txt') as f:\n",
    "    for line in f:\n",
    "        test_set.append(line.rstrip())\n",
    "\n",
    "# Check \n",
    "test_set[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set has 662675 nodes\n"
     ]
    }
   ],
   "source": [
    "# Len of test_set\n",
    "print('test set has {} nodes'.format(len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that every node in the test set exists in adj_list\n",
    "for i in test_set:\n",
    "    if i in adj_list:\n",
    "        continue\n",
    "    else:\n",
    "        print('Test set contains new nodes not in original network')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fact 1: every node in the adj_list exists in the original network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "662675"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert it to a pandas series for additional functions \n",
    "test_set = pd.Series(test_set)\n",
    "# Check\n",
    "test_set.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training set...\n",
      "Process took 1.8339 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load trainset \n",
    "print(\"Reading training set...\")\n",
    "start_time = time.time()\n",
    "\n",
    "train_df_chunks = pd.read_csv(\"../data/labeled-vertices.train.tsv\",\n",
    "                       delimiter='\\t',\n",
    "                       usecols=[0,1],\n",
    "                       names=['id', 'attr'],\n",
    "                       header=None,\n",
    "                       chunksize=100000)\n",
    "\n",
    "# Combine\n",
    "train_df =  pd.concat(train_df_chunks)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Process took {:.04f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# Free memory\n",
    "train_df_chunks = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5301403 total nodes in the training set\n",
      "Of which, 5301403 are unique\n"
     ]
    }
   ],
   "source": [
    "# Total number of rows in the training set\n",
    "print(\"There are {} total nodes in the training set\".format(train_df.shape[0]))\n",
    "# Total number of unique nodes\n",
    "print(\"Of which, {} are unique\".format(train_df['id'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5509623</td>\n",
       "      <td>T0:0 T1:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6334893</td>\n",
       "      <td>T0:0 T1:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1218900</td>\n",
       "      <td>T0:1 T1:2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3871398</td>\n",
       "      <td>T0:1 T1:2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3942361</td>\n",
       "      <td>T0:0 T1:3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       attr\n",
       "0  5509623  T0:0 T1:0\n",
       "1  6334893  T0:0 T1:1\n",
       "2  1218900  T0:1 T1:2\n",
       "3  3871398  T0:1 T1:2\n",
       "4  3942361  T0:0 T1:3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_df['id']:\n",
    "    if str(i) in test_set:\n",
    "        print('Some nodes in training set exist in the test set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## None of the nodes in the test set exist in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Use the common neighbor node pairs produced from the link prediction problem and find the node with the highest CN value and inherit their attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231167\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "      <th>CN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1091804</td>\n",
       "      <td>967845</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1091804</td>\n",
       "      <td>1354523</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1091804</td>\n",
       "      <td>2309755</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4573414</td>\n",
       "      <td>967845</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4573414</td>\n",
       "      <td>1354523</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     node1    node2   CN\n",
       "0  1091804   967845   67\n",
       "1  1091804  1354523   51\n",
       "2  1091804  2309755   68\n",
       "3  4573414   967845  101\n",
       "4  4573414  1354523   54"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_pairs = candidate_nodes = pd.read_csv('../data/candidate_pairs.csv',\n",
    "                              dtype={'node1': np.int32, 'node2': np.int32, 'CN': np.int32})\n",
    "\n",
    "# Check\n",
    "print(candidate_nodes.shape[0])\n",
    "candidate_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropping duplicates: 693501\n",
      "Number of rows after dropping duplicates: 52395\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "      <th>CN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6247815</td>\n",
       "      <td>1542000</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5401224</td>\n",
       "      <td>988315</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304552</td>\n",
       "      <td>6314086</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>353603</td>\n",
       "      <td>988315</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4258628</td>\n",
       "      <td>1542000</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     node1    node2   CN\n",
       "0  6247815  1542000  593\n",
       "1  5401224   988315  557\n",
       "2   304552  6314086  545\n",
       "5   353603   988315  497\n",
       "6  4258628  1542000  496"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by CN value and reset index\n",
    "candidate_nodes.sort_values('CN', inplace=True, ascending=False)\n",
    "candidate_nodes.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print('Number of rows before dropping duplicates: {}'.format(candidate_nodes.size))\n",
    "\n",
    "# Drop duplicates. The first match we get is the one with the highest CN.\n",
    "candidate_nodes.drop_duplicates(subset='node1', keep='first', inplace=True)\n",
    "\n",
    "print('Number of rows after dropping duplicates: {}'.format(candidate_nodes.size))\n",
    "candidate_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         True\n",
      "1         True\n",
      "2         True\n",
      "5         True\n",
      "6         True\n",
      "7         True\n",
      "8         True\n",
      "9         True\n",
      "10        True\n",
      "11        True\n",
      "12        True\n",
      "13        True\n",
      "14        True\n",
      "15        True\n",
      "16        True\n",
      "17        True\n",
      "19        True\n",
      "20        True\n",
      "21        True\n",
      "23        True\n",
      "25        True\n",
      "26        True\n",
      "27        True\n",
      "28        True\n",
      "29        True\n",
      "31        True\n",
      "32        True\n",
      "38        True\n",
      "41        True\n",
      "42        True\n",
      "          ... \n",
      "230561    True\n",
      "230566    True\n",
      "230584    True\n",
      "230595    True\n",
      "230598    True\n",
      "230602    True\n",
      "230619    True\n",
      "230637    True\n",
      "230652    True\n",
      "230656    True\n",
      "230677    True\n",
      "230720    True\n",
      "230722    True\n",
      "230725    True\n",
      "230743    True\n",
      "230745    True\n",
      "230753    True\n",
      "230775    True\n",
      "230843    True\n",
      "230846    True\n",
      "230865    True\n",
      "230902    True\n",
      "230927    True\n",
      "230945    True\n",
      "230985    True\n",
      "231004    True\n",
      "231061    True\n",
      "231156    True\n",
      "231158    True\n",
      "231162    True\n",
      "Name: node1, Length: 17465, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "for i in test_set:\n",
    "    for i, r in c_pairs.iterrows()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140294\n"
     ]
    }
   ],
   "source": [
    "for i in test_set:\n",
    "    print(candidate_nodes.node1.ne(int(i)).idxmin())\n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2494614']\n",
      "['2120159', '3119624', '2817288', '848669', '4546232', '1242663', '3191796']\n"
     ]
    }
   ],
   "source": [
    "# Solution 1: Take advantage of the common neighbors data produced earlier to find candidata nodes for a node.\n",
    "# Assume their attributes will be shared with the mystery node. \n",
    "count = 0\n",
    "for i in test_set:\n",
    "    print(adj_list[i])\n",
    "    print(adj_list[adj_list[i][0]])\n",
    "    count += 1 \n",
    "    if count == 1:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following intuition:\n",
    "1. Nodes sharing common neighbors are likely to be friends, thus share similar interests. Jaccard_similarity to find the most similar node. \n",
    "2. For nodes with few neighbors, if nodes are closer than 4 nodes away (small world phenomenon states that on averages nodes are 4 steps aways), find those nodes, rank them by connetivity (preferential attachment) and inherit the attributes of the node with the highest degree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a user x user matrix, and have the value b 0 or 1 to indicate a link. \n",
    "# Using cosine similarity, the most similar node will be returned for a target node\n",
    "# Using the similar node, use that as a key to look up its node in the training set.\n",
    "# Retrieve its attributes and assign that as the attribute for the particular node. \n",
    "\n",
    "# If multiple nodes exists, for example, using a threshold to define similarity, \n",
    "# choose the nearest one. Perhaps, I can find the shortest path for node1 - candidate node\n",
    "# then choose the closest one. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a adjacency matrix, we can assume that popular neighbors have more influence than less coneccted neighbors.\n",
    "# For a given node, find all  neighbors.\n",
    "# Return the \"most\" connected neighbor and their attributes.\n",
    "# These attributes can be the new attributes for the user. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triangular closure can indicate tight community of friends.\n",
    "# if a nighbor of a friend is friends with another nieghbor, this triangualr relationship can indicate close nit \n",
    "# circle, assume that these nodes share alot of attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD approach\n",
    "# Create a user x attribute matrix\n",
    "# presence of attribute is indicated by 1, absence is 0,\n",
    "# use this "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
