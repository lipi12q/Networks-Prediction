{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "# import igraph\n",
    "# import time\n",
    "# from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a. Create graph by reading the tsv file with networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating network graph...\n",
      "Network graph created. Process took 302.3193 seconds\n",
      "Number of edges: 30915267\n",
      "Number of nodes: 6626753\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating network graph...\")\n",
    "start_time = time.time() \n",
    "\n",
    "with open(\"../data/network.tsv\", 'rb') as f:\n",
    "    grph = nx.read_edgelist(path=f, delimiter='\\t', encoding='utf8')\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Network graph created. Process took {:.04f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# Check that graph is of correct size\n",
    "print(\"Number of edges: {}\".format(grph.number_of_edges())) # There should be 30915267\n",
    "print(\"Number of nodes: {}\".format(grph.number_of_nodes())) # There should be 6626753"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. Create graph by reading the tsv file with pandas read_csv as chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read data as chunks\n",
    "# print(\"Reading network data as chunks...\")\n",
    "# start_time = time.time()\n",
    "\n",
    "# g_data_chunks = pd.read_csv(\"./all/network.tsv\",\n",
    "#                             delimiter='\\t',\n",
    "#                             usecols=[0,1],\n",
    "#                             names=['n', 'v'],\n",
    "#                             dtype={'n': np.int32, 'v': np.int32},\n",
    "#                             header=None,\n",
    "#                             chunksize=100000)\n",
    "\n",
    "# # Combine\n",
    "# # g_data_chunks pd.concat(g_data_chunks)\n",
    "\n",
    "# end_time = time.time()\n",
    "# print(\"Chunks created. Process took {:.04f} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Creating network graph...\")\n",
    "\n",
    "# start_time = time.time() \n",
    "\n",
    "# # Initalize undirected simple graph\n",
    "# grph = nx.Graph()\n",
    "\n",
    "# # Populate the graph by adding edges from chunked dataframes\n",
    "# for chunk in g_data_chunks: \n",
    "#   grph.add_edges_from([tuple(x) for x in chunk.values])\n",
    "\n",
    "# end_time = time.time()\n",
    "\n",
    "# print(\"Network graph created. Process took {:.04f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# # Check that graph is of correct size\n",
    "# print(\"Number of edges: {}\".format(grph.number_of_edges())) # There should be 30915267\n",
    "# print(\"Number of nodes: {}\".format(grph.number_of_nodes())) # There should be 6626753"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate an adjacency list and save it as a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken and modified from stack overflow: https://stackoverflow.com/questions/34917550/write-a-\n",
    "# graph-into-a-file-in-an-adjacency-list-form-mentioning-all-neighbors-of\n",
    "\n",
    "def adj_list_to_file(G, file_name):\n",
    "    f = open(file_name, \"w\")\n",
    "    for n in G.nodes():\n",
    "        f.write(str(n) + ',')\n",
    "        for neighbor in G.neighbors(n):\n",
    "            f.write(str(neighbor) + ' ')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write save save adjacency list \n",
    "adj_list_to_file(grph, '../data/adjacency_list.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read the adjacency list file and create a dictionary from it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file and create dictionary\n",
    "adj_list = {}\n",
    "\n",
    "with open('../data/adjacency_list.txt', 'r') as f:\n",
    "    # For each line in the file, create a dictionary that has a key = node and value = edges\n",
    "    for line in f:\n",
    "        adj_list[line.split(',')[0]] = line.split(',')[1].rstrip().split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The following functions are for the fast algorithm for Common Neighbors Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_lemma1(adj_list, L):\n",
    "    '''\n",
    "    This function will filter out nodes of the adjacency list\n",
    "    if the number of their neighbors is no greater than threshold\n",
    "    L since these pairs will not have more than L common neighbors. \n",
    "    \n",
    "    For example, the following is an adjacency list\n",
    "    represented as a python dictionary. The key is a node,\n",
    "    and the value is a list of common neighbors of that node. \n",
    "    \n",
    "    {0: [1, 2, 4, 5, 7],\n",
    "     1: [0, 2, 4, 7],\n",
    "     2: [0, 1, 3, 5, 6],\n",
    "     3: [2, 4, 6, 7],\n",
    "     4: [0, 1, 3, 6],\n",
    "     5: [0, 2],\n",
    "     6: [2, 3, 4],\n",
    "     7: [0, 1, 3]}\n",
    "    \n",
    "    Setting L to 3, this function will filter out nodes that have\n",
    "    3 or less neighbors. The resulting nodes will be the following:\n",
    "            \n",
    "    {0: [1, 2, 4, 5, 7],\n",
    "     1: [0, 2, 4, 7],\n",
    "     2: [0, 1, 3, 5, 6],\n",
    "     3: [2, 4, 6, 7],\n",
    "     4: [0, 1, 3, 6]}\n",
    "    \n",
    "    :param adj_list: adjacency list of network\n",
    "    :type adj_list: dict\n",
    "    :param L: threshold for common neighbors \n",
    "    :type L: int\n",
    "    :return: adjacency list with nodes with more than L neighbors\n",
    "    :rtype: dict\n",
    "    '''\n",
    "    \n",
    "    adj_new = {}\n",
    "    \n",
    "    for k, v in adj_list.items():\n",
    "        if len(v) > L:\n",
    "            adj_new[k] = v\n",
    "            \n",
    "    return adj_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_adjacency_list(adj_list):\n",
    "    '''\n",
    "    This function will invert the adjacency matrix. \n",
    "    \n",
    "    For example, the following is an adjacency list \n",
    "    represented as a python dictionary. The key is a node,\n",
    "    and the value is a list of common neighbors of that node.\n",
    "    \n",
    "    {0: [1, 2, 4, 5, 7],\n",
    "     1: [0, 2, 4, 7],\n",
    "     2: [0, 1, 3, 5, 6],\n",
    "     3: [2, 4, 6, 7],\n",
    "     4: [0, 1, 3, 6]}\n",
    "     \n",
    "    Starting with node 1, we see that it appears in the \n",
    "    adjacency list of node 0, 2, and 4. Thus, the inverted\n",
    "    representation will be '1: [0, 2, 4]'. The resulting\n",
    "    inverted adjaceny list will be the following: \n",
    "        \n",
    "    {0: [1, 2, 4],\n",
    "     1: [0, 2, 4],\n",
    "     2: [0, 1, 3],\n",
    "     3: [2, 4],\n",
    "     4: [0, 1, 3],\n",
    "     5: [0, 2],\n",
    "     6: [2, 3, 4],\n",
    "     7: [0, 1, 3]}\n",
    "    \n",
    "    :param adj_list: adjacency list of network\n",
    "    :type adj_list: dict\n",
    "    :return: inverted adjacency list of network \n",
    "    :rtype: dict\n",
    "    '''\n",
    "    \n",
    "    adj_inv = {}\n",
    "    \n",
    "    for k, v in adj_list.items():\n",
    "        for i in v:\n",
    "            if i in adj_inv:\n",
    "                adj_inv[i].append(k)\n",
    "            else:\n",
    "                adj_inv[i] = [k]\n",
    "            \n",
    "    return adj_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_accompanied_groups(adj_list):\n",
    "    '''\n",
    "    This function generates all accompanied groups in address and\n",
    "    size representation. \n",
    "    \n",
    "    For example, node 4 is present in the adjacency list of node 0. \n",
    "    \n",
    "    {0: [1, 2, 4],\n",
    "     1: [0, 2, 4],\n",
    "     2: [0, 1, 3],\n",
    "     3: [2, 4],\n",
    "     4: [0, 1, 3],\n",
    "     5: [0, 2],\n",
    "     6: [2, 3, 4],\n",
    "     7: [0, 1, 3]}\n",
    "    \n",
    "    Since this is the adjacency list of node 0, the address is 0. The \n",
    "    ranking of a node is equal to the size of the accompanied group. For\n",
    "    node 4, the size of the accompanying group '[1, 2]' is 2. The accompanied\n",
    "    group in the address, size representation would be '{4: (0, 2)}'. The\n",
    "    resulting accompanied groups will be the following: \n",
    "    \n",
    "    {1: [(2, 1), (4, 1), (7, 1)],\n",
    "     2: [(1, 1), (5, 1), (0, 1)],\n",
    "     3: [(2, 2), (4, 2), (7, 2), (6, 1)],\n",
    "     4: [(1, 2), (0, 2), (3, 1), (6, 2)]}\n",
    "    \n",
    "    :param adj_list: lemma2 filtered adjacency list of network\n",
    "    :type adj_list: dict\n",
    "    :param L: threshold for common neighbors \n",
    "    :type L: int\n",
    "    :return: accompanied groups in (adj adress, size) representation. \n",
    "    :rtype: dict\n",
    "    '''\n",
    "    \n",
    "    acc_group = {}\n",
    "    \n",
    "    # Find accompanied groups of nodes by address and size \n",
    "    for k, v in adj_list.items():\n",
    "        for i in range(1, len(v)):\n",
    "            if v[i] in acc_group:\n",
    "                acc_group[v[i]].append((k, i))\n",
    "            else:\n",
    "                acc_group[v[i]] = [(k, i)]\n",
    "\n",
    "    return acc_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_lemma2(acc_group, L):\n",
    "    '''\n",
    "    This function will filter out accompanied groups no greater than\n",
    "    threshold L. After filtering by lemma 1, if node 'u' appears at most\n",
    "    in L node adjacencies (having no greater than L accompanied groups),\n",
    "    the common neighbor of any node pair containing 'u' will be no \n",
    "    greater than L. \n",
    "    \n",
    "    For example, the following is a python dictionary representing the\n",
    "    accompanied groups of a network. \n",
    "    \n",
    "    {1: [(2, 1), (4, 1), (7, 1)],\n",
    "     2: [(1, 1), (5, 1), (0, 1)],\n",
    "     3: [(2, 2), (4, 2), (7, 2), (6, 1)],\n",
    "     4: [(1, 2), (0, 2), (3, 1), (6, 2)]}\n",
    "    \n",
    "    Setting L to 3, this function will filter out nodes that have\n",
    "    3 or less groups. The resulting accompanied groups will be the\n",
    "    following:\n",
    "    \n",
    "    {3: [(2, 2), (4, 2), (7, 2), (6, 1)],\n",
    "     4: [(1, 2), (0, 2), (3, 1), (6, 2)]}\n",
    "    \n",
    "    :param acc_group: accompanied groups \n",
    "    :type acc_group: dict\n",
    "    :param L: threshold for common neighbors \n",
    "    :type L: int\n",
    "    :return: accompanied groups greater than L\n",
    "    :rtype: dict\n",
    "    '''\n",
    "    \n",
    "    f_acc_group = {}\n",
    "    \n",
    "    # Filter by L\n",
    "    for k, v in acc_group.items():\n",
    "        if len(v) > L:\n",
    "            f_acc_group[k] = v\n",
    "    \n",
    "    return f_acc_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_node_pairs(acc_group, adj_list, L):\n",
    "    '''\n",
    "    This function will generate node pairs with common neighbors greater \n",
    "    than threshold L. \n",
    "    \n",
    "    For example, the following is a python dictionary representing the \n",
    "    accompanied groups of a network.\n",
    "    \n",
    "    {3: [(2, 2), (4, 2), (7, 2), (6, 1)],\n",
    "     4: [(1, 2), (0, 2), (3, 1), (6, 2)]}\n",
    "\n",
    "    Rember that the accompanied groups are in (address, size) format. Looking\n",
    "    at the first group for node 4, the address is pointing to adjacency list\n",
    "    1, and the size is 2. Take a look at the following adjacency list:\n",
    "    \n",
    "    {0: [1, 2, 4],\n",
    "     1: [0, 2, 4],\n",
    "     2: [0, 1, 3],\n",
    "     3: [2, 4],\n",
    "     4: [0, 1, 3],\n",
    "     5: [0, 2],\n",
    "     6: [2, 3, 4],\n",
    "     7: [0, 1, 3]}\n",
    "    \n",
    "    Looking at node 1's adjacency list, the 2 other nodes accompanying \n",
    "    node 4 are 0 and 2. This means that node 0, 2, and 4 share the same\n",
    "    common neighbor node 1. If we look up the address and size for all \n",
    "    groups and calculate the total common neighbors shared, we get the \n",
    "    following: \n",
    "    \n",
    "       |_0_|_1_|_2_|_3_|\n",
    "     3 | 3 | 2 | 2 |   | \n",
    "     4 | 1 | 1 | 1 | 1 |\n",
    "     \n",
    "    :param acc_group: accompanied groups\n",
    "    :type acc_group: dict\n",
    "    :param adj_list: adjacency list filtered by lemma1 and lemma2 \n",
    "    :type adj_list: dict\n",
    "    :return: node pairs and CN values\n",
    "    :rtype: dict\n",
    "    '''\n",
    "\n",
    "    node_pairs = {}\n",
    "    \n",
    "    for k, v in acc_group.items():\n",
    "        for i in v:\n",
    "            # Read adjaceny list up to size (rank)\n",
    "            for j in adj_list[i[0]][:i[1]]:\n",
    "                node_pairs[(k, j)] = node_pairs.get((k, j), 0) + 1 \n",
    "    \n",
    "    filtered_node_pairs = []\n",
    "    \n",
    "    for k, v in node_pairs.items():\n",
    "        if v > L:\n",
    "            filtered_node_pairs.append((k, v))\n",
    "    \n",
    "    return filtered_node_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST that the functions work properly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = {\n",
    "    0: [1, 2, 4, 5, 7],\n",
    "    1: [0, 2, 4, 7],\n",
    "    2: [0, 1, 3, 5, 6],\n",
    "    3: [2, 4, 6, 7],\n",
    "    4: [0, 1, 3, 6],\n",
    "    5: [0, 2],\n",
    "    6: [2, 3, 4],\n",
    "    7: [0, 1, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process took 0.00018 seconds\n",
      "TEST_1 output\n",
      "{0: [1, 2, 4, 5, 7],\n",
      " 1: [0, 2, 4, 7],\n",
      " 2: [0, 1, 3, 5, 6],\n",
      " 3: [2, 4, 6, 7],\n",
      " 4: [0, 1, 3, 6]}\n",
      "TEST_2 output\n",
      "{0: [1, 2, 4],\n",
      " 1: [0, 2, 4],\n",
      " 2: [0, 1, 3],\n",
      " 3: [2, 4],\n",
      " 4: [0, 1, 3],\n",
      " 5: [0, 2],\n",
      " 6: [2, 3, 4],\n",
      " 7: [0, 1, 3]}\n",
      "TEST_3 output\n",
      "{1: [(2, 1), (4, 1), (7, 1)],\n",
      " 2: [(1, 1), (5, 1), (0, 1)],\n",
      " 3: [(2, 2), (4, 2), (7, 2), (6, 1)],\n",
      " 4: [(1, 2), (0, 2), (3, 1), (6, 2)]}\n",
      "TEST_4 output\n",
      "{3: [(2, 2), (4, 2), (7, 2), (6, 1)], 4: [(1, 2), (0, 2), (3, 1), (6, 2)]}\n",
      "TEST_5 output\n",
      "[((4, 2), 4)]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() \n",
    "\n",
    "TEST_1 = filter_by_lemma1(TEST, 3)\n",
    "TEST_2 = invert_adjacency_list(TEST_1)\n",
    "TEST_3 = generate_accompanied_groups(TEST_2)\n",
    "TEST_4 = filter_by_lemma2(TEST_3, 3)\n",
    "TEST_5 = generate_node_pairs(TEST_4, TEST_2, 3)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Process took {:.05f} seconds\".format(end_time - start_time))\n",
    "\n",
    "print('TEST_1 output')\n",
    "pprint(TEST_1)\n",
    "print('TEST_2 output')\n",
    "pprint(TEST_2)\n",
    "print('TEST_3 output')\n",
    "pprint(TEST_3)\n",
    "print('TEST_4 output')\n",
    "pprint(TEST_4)\n",
    "print('TEST_5 output')\n",
    "pprint(TEST_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest \n",
    "\n",
    "class TestFilter(unittest.TestCase):\n",
    "    \n",
    "    # Run before every single test\n",
    "    def setUp(self):\n",
    "        self.adj_list_1 = {0: [1, 2, 4, 5, 7],\n",
    "                           1: [0, 2, 4, 7],\n",
    "                           2: [0, 1, 3, 5, 6],\n",
    "                           3: [2, 4, 6, 7],\n",
    "                           4: [0, 1, 3, 6],\n",
    "                           5: [0, 2],\n",
    "                           6: [2, 3, 4],\n",
    "                           7: [0, 1, 3]}\n",
    "        \n",
    "        self.adj_list_2 = {0: [1, 2, 4, 5, 7],\n",
    "                           1: [0, 2, 4, 7],\n",
    "                           2: [0, 1, 3, 5, 6],\n",
    "                           3: [2, 4, 6, 7],\n",
    "                           4: [0, 1, 3, 6]}\n",
    "                            \n",
    "        self.inv_list = {0: [1, 2, 4],\n",
    "                         1: [0, 2, 4],\n",
    "                         2: [0, 1, 3],\n",
    "                         3: [2, 4],\n",
    "                         4: [0, 1, 3],\n",
    "                         5: [0, 2],\n",
    "                         6: [2, 3, 4],\n",
    "                         7: [0, 1, 3]}\n",
    "        \n",
    "        self.acc_group_1 = {1: [(2, 1), (4, 1), (7, 1)],\n",
    "                            2: [(1, 1), (5, 1), (0, 1)],\n",
    "                            3: [(2, 2), (4, 2), (7, 2), (6, 1)],\n",
    "                            4: [(1, 2), (0, 2), (3, 1), (6, 2)]}\n",
    "        \n",
    "        self.acc_group_2 = {3: [(2, 2), (4, 2), (7, 2), (6, 1)], \n",
    "                            4: [(1, 2), (0, 2), (3, 1), (6, 2)]}\n",
    "        \n",
    "        self.pair_node = [[(4, 2), 4]]\n",
    "    \n",
    "    def test_filter_lemma1(self):\n",
    "        print(\"Test filter lemma 1...\")\n",
    "        self.assertEqual(filter_by_lemma1(self.adj_list_A, 3), self.adj_list_B)\n",
    "    \n",
    "    def test_inverted_adjacency_list(self):\n",
    "        print(\"Test filter lemma 2...\")\n",
    "        self.assertEqual(filter_by_lemma2(self.adj_listB), self.adj_list_C)\n",
    "    \n",
    "    def test_both_lemma_filters(self):\n",
    "        print(\"Test both lemma filters...\")\n",
    "        self.assertEqual(filter_by_lemma2(filter_by_lemma1(self.adj_listA)), self.adj_list_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate candidate node pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Threshold\n",
    "L = 100\n",
    "\n",
    "print(\"Step 1: Filter adjacency list\")\n",
    "f_adj_list = filter_by_lemma1(adj_list, L)\n",
    "\n",
    "print(\"Step 2: Invert adjacency list\")\n",
    "inv_adj_list = invert_adjacency_list(f_adj_list)\n",
    "\n",
    "# Clear Variables\n",
    "f_adj_list = None\n",
    "\n",
    "print(\"Step 3: Create accompanied groups\")\n",
    "acc_groups = generate_accompanied_groups(inv_adj_list)\n",
    "\n",
    "print(\"Step 4: Filter accompanied groups\")\n",
    "f_acc_groups = filter_by_lemma2(acc_groups, L)\n",
    "\n",
    "# Clear variables\n",
    "acc_groups = None\n",
    "\n",
    "candidate_node_pairs = generate_node_pairs(f_acc_groups, inv_adj_list, L)\n",
    "print(\"*****Done*****\")\n",
    "\n",
    "# Clear variables\n",
    "f_acc_groups = None\n",
    "inv_adj_list = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save candidate ndoes as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_candidate_pairs(c_pairs, file_name):\n",
    "    with open(file_name, \"w\") as f:\n",
    "        f.write('node1, node2, CN\\n')\n",
    "        for i in c_pairs:\n",
    "            f.write('{}, {}, {}\\n'.format(i[0][0], i[0][1], i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save \n",
    "save_candidate_pairs(candidate_node_pairs, '../data/candidate_pairs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resulting nodes are the node pairs that have common neighbors above a certain threshold. From this list, for nodes that are not yet already connected, find the most likely pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_prediction(g):\n",
    "    # Get all node connectivity relationships to exclude them later for similarity calculation \n",
    "    if "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "networkx uses a dict structure which takes up a lot of memory. \n",
    "https://graph-tool.skewed.de/performance\n",
    "igraph is implemented in C. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
