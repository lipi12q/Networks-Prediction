{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import igraph\n",
    "# import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7.1\n"
     ]
    }
   ],
   "source": [
    "print(igraph.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading network data and creating graph...\n",
      "Network graph created. Process took 199.2736 seconds\n",
      "We expect there to be 6626753 vertices. The graph has 6626753 vertices.\n",
      "We expect there to be 30915267 edges. The graph has 30915267 edges\n"
     ]
    }
   ],
   "source": [
    "# Load the network edgelist file and create the graph \n",
    "start_time = time.time()\n",
    "\n",
    "print(\"Reading network data and creating graph...\")\n",
    "\n",
    "g = igraph.Graph.Read_Ncol('../data/network.tsv', directed=False)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Network graph created. Process took {:.04f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# Check that the graph was created correctly\n",
    "print(\"We expect there to be 6626753 vertices. The graph has {} vertices.\".format(g.vcount()))\n",
    "print(\"We expect there to be 30915267 edges. The graph has {} edges\".format(g.ecount()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken and modified from stack overflow: https://stackoverflow.com/questions/34917550/write-\n",
    "# a-graph-into-a-file-in-an-adjacency-list-form-mentioning-all-neighbors-of\n",
    "\n",
    "def adj_list_to_file(G, file_name):\n",
    "    f = open(file_name, \"w\")\n",
    "    for n in G.vs:\n",
    "        f.write(str(n) + ',')\n",
    "        for neighbor in G.neighbors(n):\n",
    "            f.write(str(neighbor) + ' ')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write save save adjacency list \n",
    "adj_list_to_file(g, '../adjacency_list_2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading network data as chunks...\n",
      "Chunks created. Process took 0.0036 seconds\n"
     ]
    }
   ],
   "source": [
    "# # Read data as chunks\n",
    "# print(\"Reading network data as chunks...\")\n",
    "# start_time = time.time()\n",
    "\n",
    "# g_data_chunks = pd.read_csv(\"./all/network.tsv\",\n",
    "#                             delimiter='\\t',\n",
    "#                             usecols=[0,1],\n",
    "#                             names=['n', 'v'],\n",
    "#                             dtype={'n': np.int32, 'v': np.int32},\n",
    "#                             header=None,\n",
    "#                             chunksize=100000)\n",
    "\n",
    "# # Combine\n",
    "# # g_data_chunks pd.concat(g_data_chunks)\n",
    "\n",
    "# end_time = time.time()\n",
    "# print(\"Chunks created. Process took {:.04f} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30915267"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Check number of rows\n",
    "# g_data_full.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_data_chunks = [x for x in g_data_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating network graph...\n",
      "Network graph created. Process took 225.2254 seconds\n"
     ]
    }
   ],
   "source": [
    "# print(\"Creating network graph...\")\n",
    "# start_time = time.time() \n",
    "\n",
    "# with open(\"./all/network.tsv\", 'rb') as f:\n",
    "#     grph = nx.read_edgelist(path=f, delimiter='\\t', encoding='utf8')\n",
    "\n",
    "# end_time = time.time()\n",
    "# print(\"Network graph created. Process took {:.04f} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating network graph...\n",
      "Network graph created. Process took 220.6446 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating network graph...\")\n",
    "\n",
    "start_time = time.time() \n",
    "\n",
    "# Initalize undirected simple graph\n",
    "grph = nx.Graph()\n",
    "\n",
    "# Populate the graph by adding edges from chunked dataframes\n",
    "for chunk in g_data_chunks: \n",
    "  grph.add_edges_from([tuple(x) for x in chunk.values])\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Network graph created. Process took {:.04f} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges: 30915267\n",
      "Number of nodes: 6626753\n"
     ]
    }
   ],
   "source": [
    "# Check that graph is of correct size\n",
    "print(\"Number of edges: {}\".format(grph.number_of_edges())) # There should be 30915267\n",
    "print(\"Number of nodes: {}\".format(grph.number_of_nodes())) # There should be 6626753"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeDataView([(4009630, 3942361), (4009630, 4251483), (4009630, 2072811), (4009630, 3086356), (4009630, 5077327), (4009630, 846118), (4009630, 3776891), (4009630, 4312881), (4009630, 4950631), (4009630, 2544100), (4009630, 4507852), (4009630, 3970312), (4009630, 5650628), (4009630, 5161251), (4009630, 370884), (4009630, 2686972), (4009630, 1177053), (4009630, 3696168)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all edges for node 4009630\n",
    "# The result will be the node, followed by nodes its connected to\n",
    "grph.edges(4009630)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken and modified from stack overflow: https://stackoverflow.com/questions/34917550/write-a-graph-into-a-file-in-an-adjacency-list-form-mentioning-all-neighbors-of\n",
    "def adj_list_to_file(G, file_name):\n",
    "    f = open(file_name, \"w\")\n",
    "    for n in G.nodes():\n",
    "        f.write(str(n) + ',')\n",
    "        for neighbor in G.neighbors(n):\n",
    "            f.write(str(neighbor) + ' ')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write save save adjacency list \n",
    "adj_list_to_file(grph, './adjacency_list.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load text into pandas df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file and create dictionary\n",
    "adj_list = {}\n",
    "\n",
    "with open('./adjacency_list.txt', 'r') as f:\n",
    "    # For each line in the file, create a dictionary that has a key = node and value = edges\n",
    "    c = 0 \n",
    "    for line in f:\n",
    "        adj_list[line.split(',')[0]] = line.split(',')[1].rstrip().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify constant L for filtering by nodes Common Neighbors\n",
    "def filter_by_lemma1(adj_list, L):\n",
    "    '''\n",
    "    If the number of neighbors of a node is not greater than L, \n",
    "    remove the node pairs that contain that node since these\n",
    "    pairs will not have more than L common neighbors. \n",
    "    \n",
    "    :params adj_list: adjacency list of network\n",
    "    :type adj_list: dict\n",
    "    :params L: threshold for common neighbors \n",
    "    :type L: int\n",
    "    :return: adjacency list with nodes that satisfy the threshold\n",
    "    :rtype: dict\n",
    "    '''\n",
    "    \n",
    "    adj_new = {}\n",
    "    \n",
    "    for k, v in adj_list.items():\n",
    "        if len(v) > L:\n",
    "            adj_new[k] = v\n",
    "            \n",
    "    return adj_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_lemma2(adj_list):\n",
    "    '''\n",
    "    In the remaining network after filtering by lemma 1, \n",
    "    if a node appears at most in L node adjacencies, \n",
    "    this node will not have more than L common neighbors. \n",
    "    \n",
    "    :params adj_list: adjacency list of network\n",
    "    :type adj_list: dict\n",
    "    :return: inverted adjacency list of network \n",
    "    :rtype: dict\n",
    "    '''\n",
    "    \n",
    "    adj_inv = {}\n",
    "    \n",
    "    for k, v in adj_list.items():\n",
    "        for i in v:\n",
    "            if i in adj_inv:\n",
    "                adj_inv[i].append(k)\n",
    "            else:\n",
    "                adj_inv[i] = [k]\n",
    "            \n",
    "    return adj_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = {\n",
    "    0: [1, 2, 4, 5, 7],\n",
    "    1: [0, 2, 4, 7],\n",
    "    2: [0, 1, 3, 5, 6],\n",
    "    3: [2, 4, 6, 7],\n",
    "    4: [0, 1, 3, 6],\n",
    "    5: [0, 2],\n",
    "    6: [2, 3, 4],\n",
    "    7: [0, 1, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [1, 2, 4, 5, 7],\n",
       " 1: [0, 2, 4, 7],\n",
       " 2: [0, 1, 3, 5, 6],\n",
       " 3: [2, 4, 6, 7],\n",
       " 4: [0, 1, 3, 6]}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_filter1 = filter_by_lemma1(TEST, 3)\n",
    "TEST_filter1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [0, 2, 4],\n",
       " 2: [0, 1, 3],\n",
       " 4: [0, 1, 3],\n",
       " 5: [0, 2],\n",
       " 7: [0, 1, 3],\n",
       " 0: [1, 2, 4],\n",
       " 3: [2, 4],\n",
       " 6: [2, 3, 4]}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_filter2 = filter_by_lemma2(TEST_filter1)\n",
    "TEST_filter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_accompanied_groups(adj_list):\n",
    "    '''\n",
    "    Generate all accompanied groups in address and size representation. \n",
    "    \n",
    "    For example, 4 is a node at adjacency list 0 '[1, 2, 4]', and the \n",
    "    ranking of 4 in adjacency list 0 is equal to the size of the \n",
    "    accompanied group to 4, which is two.  \n",
    "    \n",
    "    The output for this node would look like the following: [4, (0, 2)]\n",
    "    \n",
    "    :params adj_list: lemma2 filtered adjacency list of network\n",
    "    :type adj_list: dict\n",
    "    :params L: threshold for common neighbors \n",
    "    :type L: int\n",
    "    :return: accompanied groups in (adj adress, size) representation. \n",
    "    :rtype: dict\n",
    "    '''\n",
    "    \n",
    "    acc_group = {}\n",
    "    \n",
    "    # Find accompanied groups of nodes by address and size \n",
    "    for k, v in adj_list.items():\n",
    "        for i in range(1, len(v)):\n",
    "            if v[i] in acc_group:\n",
    "                acc_group[v[i]].append((k, i))\n",
    "            else:\n",
    "                acc_group[v[i]] = [(k, i)]\n",
    "\n",
    "    return acc_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: [(1, 1), (5, 1), (0, 1)],\n",
       " 4: [(1, 2), (0, 2), (3, 1), (6, 2)],\n",
       " 1: [(2, 1), (4, 1), (7, 1)],\n",
       " 3: [(2, 2), (4, 2), (7, 2), (6, 1)]}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_accompanied_group = generate_accompanied_groups(TEST_filter2)\n",
    "TEST_accompanied_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_accompanied_groups(acc_group, L):\n",
    "    '''\n",
    "    Filter accompanied groups by threshold L.\n",
    "    \n",
    "    :params acc_group: accompanied groups \n",
    "    :type acc_group: dict\n",
    "    :params L: threshold for common neighbors \n",
    "    :type L: int\n",
    "    :return: accompanied groups greater than L\n",
    "    :rtype: dict\n",
    "    '''\n",
    "    \n",
    "    f_acc_group = {}\n",
    "    \n",
    "    # Filter by L\n",
    "    for k, v in acc_group.items():\n",
    "        if len(v) > L:\n",
    "            f_acc_group[k] = v\n",
    "    \n",
    "    return f_acc_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: [(1, 2), (0, 2), (3, 1), (6, 2)], 3: [(2, 2), (4, 2), (7, 2), (6, 1)]}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_Filtered_AC = filter_accompanied_groups(TEST_accompanied_group, 3)\n",
    "TEST_Filtered_AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_node_pairs(acc_group, adj_list, L):\n",
    "    '''\n",
    "    Accept filtered accompanied groups and generate node pairs and\n",
    "    corresponding common neighbor values.\n",
    "    \n",
    "    :params acc_group: accompanied groups\n",
    "    :type acc_group: dict\n",
    "    :params adj_list: adjacency list filtered by lemma1 and lemma2 \n",
    "    :type adj_list: dict\n",
    "    :return: node pairs and CN values\n",
    "    :rtype: dict\n",
    "    '''\n",
    "\n",
    "    node_pairs = {}\n",
    "    \n",
    "    for k, v in acc_group.items():\n",
    "        for i in v:\n",
    "            # Read adjaceny list up to size \n",
    "            for j in adj_list[i[0]][:i[1]]:\n",
    "                node_pairs[(k, j)] = node_pairs.get((k, j), 0) + 1 \n",
    "    \n",
    "    filtered_node_pairs = []\n",
    "    \n",
    "    for k, v in node_pairs.items():\n",
    "        if v > L:\n",
    "            filtered_node_pairs.append([k, v])\n",
    "    \n",
    "    return filtered_node_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(4, 2), 4]]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = generate_node_pairs(TEST_Filtered_AC, TEST_filter2, 3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest \n",
    "\n",
    "class TestFilter(unittest.TestCase):\n",
    "    \n",
    "    # Run before every single test\n",
    "    def setUp(self):\n",
    "        self.adj_list_A = {0: [1, 2, 3, 4, 5],\n",
    "                           1: [0, 2, 4],\n",
    "                           2: [0, 1, 4, 5],\n",
    "                           3: [0],\n",
    "                           4: [0, 1, 2],\n",
    "                           5: [0, 2]}\n",
    "        \n",
    "        self.adj_list_B = {0: [1, 2, 3, 4, 5],\n",
    "                           2: [0, 1, 4, 5]}\n",
    "        \n",
    "        self.adj_list_C = {0: [2],\n",
    "                           1: [0, 2],\n",
    "                           2: [0],\n",
    "                           3: [0],\n",
    "                           4: [0, 2],\n",
    "                           5: [0, 2]}\n",
    "    \n",
    "    def test_filter_lemma1(self):\n",
    "        print(\"Test filter lemma 1...\")\n",
    "        self.assertEqual(filter_by_lemma1(self.adj_list_A, 3), self.adj_list_B)\n",
    "    \n",
    "    def test_filter_lemma2(self):\n",
    "        print(\"Test filter lemma 2...\")\n",
    "        self.assertEqual(filter_by_lemma2(self.adj_listB), self.adj_list_C)\n",
    "    \n",
    "    def test_both_lemma_filters(self):\n",
    "        print(\"Test both lemma filters...\")\n",
    "        self.assertEqual(filter_by_lemma2(filter_by_lemma1(self.adj_listA)), self.adj_list_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E\n",
      "======================================================================\n",
      "ERROR: /Users/koki/Library/Jupyter/runtime/kernel-9817c219-911b-46f9-8dcf-f6cd17d89a34 (unittest.loader._FailedTest)\n",
      "----------------------------------------------------------------------\n",
      "AttributeError: module '__main__' has no attribute '/Users/koki/Library/Jupyter/runtime/kernel-9817c219-911b-46f9-8dcf-f6cd17d89a34'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.004s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koki/Documents/Learning/UMICH_course_material/SI_671_Data_Mining/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3273: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_prediction(g):\n",
    "    # Get all node connectivity relationships to exclude them later for similarity calculation \n",
    "    if "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "networkx uses a dict structure which takes up a lot of memory. \n",
    "https://graph-tool.skewed.de/performance\n",
    "igraph is implemented in C. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
